[
    {
        "file_name": "2106.00001.pdf",
        "title": "2106.00001",
        "year": "2021",
        "full_text": "Privately Learning Subspaces\nVikrant Singhal *\nThomas Steinke†\nAbstract\nPrivate data analysis suffers a costly curse of dimensionality. However, the data often has\nan underlying low-dimensional structure. For example, when optimizing via gradient de-\nscent, the gradients often lie in or near a low-dimensional subspace. If that low-dimensional\nstructure can be identiﬁed, then we can avoid paying (in terms of privacy or accuracy) for\nthe high ambient dimension.\nWe present differentially private algorithms that take input data sampled from a low-\ndimensional linear subspace (possibly with a small amount of error) and output that subspace\n(or an approximation to it). These algorithms can serve as a pre-processing step for other\nprocedures.\n1\nIntroduction\nDifferentially private algorithms generally have a poor dependence on the dimensionality of\ntheir input. That is, their error or sample complexity grows polynomially with the dimension.\nFor example, for the simple task of estimating the mean of a distribution supported on [0,1]d,\nwe have per-coordinate error Θ(\n√\nd/n) to attain differential privacy, where n is the number of\nsamples. In contrast, the non-private error is Θ(\np\nlog(d)/n).\nThis cost of dimensionality is inherent [BUV14; SU17; DSSUV15]. Any method with lower\nerror is susceptible to tracing attacks (a.k.a. membership inference attacks). However, these\nlower bounds only apply when the data distribution is “high-entropy.” This leaves open the\nposssibility that we can circumvent the curse of dimensionality when the data has an underlying\nlow-dimensional structure.\nData often does possess an underlying low-dimensional structure. For example, the gradients\nthat arise in deep learning tend to be close to a low-dimensional subspace [ACGMMTZ16;\nLXTSG17; GARD18; LFLY18; LGZCB20; ZWB20; FT20]. Low dimensionality can arise from\nmeaningful relationships that are at least locally linear, such as income versus tax paid. It can\nalso arise because we are looking at a function of data with relatively few attributes.\nA long line of work [BLR08; HT10; HR10; Ull15; BBNS19; BCMNUW20; ZWB20; KRRT20,\netc.] has shown how to exploit structure in the data to attain better privacy and accuracy.\n*Northeastern University.\nPart of this work was done during an internship at IBM Research – Al-\nmaden. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . singhal.vi@northeastern.edu\n†Google\nResearch,\nBrain\nTeam.\nPart\nof\nthis\nwork\nwas\ndone\nat\nIBM\nResearch\n–\nAl-\nmaden. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . subspace@thomas-steinke.net\n1\narXiv:2106.00001v3  [cs.CR]  10 Aug 2021\nHowever, these approaches assume that this structure is known a priori or that it can be learned\nfrom non-private sources. This raises the question:\nCan we learn low-dimensional structure from the data subject to differential privacy?\nWe consider the simple setting where the data lies in Rd but is in, or very close to a linear sub-\nspace, of dimension k. We focus on the setting where k ≪d and we develop algorithms whose\nsample complexity does not depend on the ambient dimension d; a polynomial dependence on\nthe true dimension k is unavoidable.\nOur algorithms identify the subspace in question or, if the data is perturbed slightly, an\napproximation to it. Identifying the subspace structure is interesting in its own right, but it also\ncan be used as a pre-processing step for further analysis – by projecting to the low-dimensional\nsubspace, we ensure subsequent data analysis steps do not need to deal with high-dimensional\ndata.\n1.1\nOur Contributions: Privately Learning Subspaces – Exact Case\nWe ﬁrst consider the exact case, where the data X1,··· ,Xn ∈Rd are assumed to lie in a\nk-dimensional subspace (rather than merely being near to it) – i.e., rank(A) = k, where A =\nPn\ni XiXT\ni ∈Rd×d. In this case, we can also recover the subspace exactly.\nHowever, we must also make some non-degeneracy assumptions. We want to avoid a\npathological input dataset such as the following. Suppose X1,··· ,Xk are linearly independent,\nbut Xk = Xk+1 = Xk+2 = ··· = Xn. While we can easily reveal the repeated data point, we cannot\nreveal anything about the other points due to the privacy constraint.\nA natural non-degeneracy assumption would be to assume that the data points are in\n“general position” – that is, that there are no non-trivial linear dependencies among the data\npoints. This means that every set of k data points spans the subspace or, equivalently, no subspace\nof dimension k −1 contains more than k −1 data points. This is a very natural assumption – if\nthe data consists of n samples from a continuous distribution on the subspace, then this holds\nwith probability 1. We relax this assumption slightly and assume that no subspace of dimension\nk −1 contains more than ℓdata points. We also assume that all points are non-zero. Note that\nwe deﬁne subspaces to pass through the origin; our results can easily be extended to afﬁne\nsubspaces.\nTheorem 1.1 (Main Result – Exact Case). For all n,d,k,ℓ∈N and ε,δ > 0 satisfying n ≥O\n\u0010\nℓ+ log(1/δ)\nε\n\u0011\n,\nthere exists a randomized algorithm M : Rd×n →Sk\nd satisfying the following. Here Sk\nd denotes the set of\nall k-dimensional subspaces of Rd.\n• M is (ε,δ)-differentially private with respect to changing one column of its input.\n• Let X = (X1,··· ,Xn) ∈Rd×n. Suppose there exists a k-dimensional subspace S∗∈Sk\nd that contains\nall but ℓof the points – i.e., |{i ∈[n] : Xi ∈S∗}| ≥n−ℓ. Further suppose that any (k−1)-dimensional\nsubspace contains at most ℓpoints – i.e., for all S ∈Sk−1\nd\n, we have |{i ∈[n] : Xi ∈S}| ≤ℓ. Then\nP[M(X) = S∗] = 1.\n2\nThe parameter ℓin Theorem 1.1 can be thought of as a robustness parameter. Ideally the\ndata points are in general position, in which case ℓ= k −1. If a few points are corrupted, then we\nincrease ℓaccordingly; our algorithm can tolerate the corruption of a small constant fraction of\nthe data points. Theorem 1.1 is optimal in the sense that n ≥Ω\n\u0010\nℓ+ log(1/δ)\nε\n\u0011\nsamples are required.\n1.2\nOur Contributions: Privately Learning Subspaces – Approximate Case\nNext we turn to the substantially more challenging approximate case, where the data\nX1,··· ,Xn ∈Rd are assumed to be close to a k-dimensional subspace, but are not assumed to be\ncontained within that subspace. Our algorithm for the exact case is robust to changing a few\npoints, but very brittle if we change all the points by a little bit. Tiny perturbations of the data\npoints (due to numerical errors or measurement imprecision) could push the point outside the\nsubspace, which would cause the algorithm to fail. Thus it is important to for us to cover the\napproximate case and our algorithm for the approximate is entirely different from our algorithm\nfor the exact case.\nThe approximate case requires us to precisely quantify how close the input data and our\noutput are to the subspace and we also need to make quantitative non-degeneracy assumptions.\nIt is easiest to formulate this via a distributional assumption. We will assume that the data\ncomes from a Gaussian distribution where the covariance matrix has a certain eigenvalue gap.\nThis is a strong assumption and we emphasize that this is only for ease of presentation; our\nalgorithm works under weaker assumptions. Furthermore, we stress that the differential privacy\nguarantee is worst-case and does not depend on any distributional assumptions.\nWe assume that the data is drawn from a multivariate Gaussian N (0,Σ). Let λ1(Σ) ≥\nλ2(Σ) ≥··· ≥λd(Σ) be the eigenvalues of Σ ∈Rd×d. We assume that there are k large eigen-\nvalues λ1(Σ),··· ,λk(Σ) – these represent the “signal” we want – and d −k small eigenvalues\nλk+1(Σ),··· ,λd(Σ) – these are the “noise”. Our goal is to recover the subspace spanned by the\neigenvectors corresponding to the k largest eigenvalues λ1(Σ),··· ,λk(Σ). Our assumption is that\nthere is a large multiplicative gap between the large and small eigenvalues. Namely, we assume\nλk+1(Σ)\nλk(Σ) ≤\n1\npoly(d).\nTheorem 1.2 (Main Result – Approximate Case). For all n,d,k ∈N and α,γ,ε,δ > 0 satisfying\nn≥Θ\n k log(1/δ)\nε\n+ ln(1/δ)ln(ln(1/δ)/ε)\nε\n!\nand γ2 ≤Θ\n \nεα2n\nd2k log(1/δ) ·min\n(1\nk ,\n1\nlog(k log(1/δ)/ε)\n)!\n,\nthere exists an algorithm M : Rd×n →Sk\nd satisfying the following. Here Sk\nd is the set of all k-dimensional\nsubspaces of Rd represented as projection matricies – i.e., Sk\nd = {Π ∈Rd×d : Π2 = Π = ΠT ,rank(Π) = k}.\n• M is (ε,δ)-differentially private with respect to changing one column of its input.\n• Let X1,··· ,Xn be independent samples from N (0,Σ). Let λ1(Σ) ≥λ2(Σ) ≥··· ≥λd(Σ) be the\neigenvalues of Σ ∈Rd×d. Suppose λk+1(Σ) ≤γ2 · λk(Σ). Let Π ∈Sk\nd be the projection matrix onto\nthe subspace spanned by the eigenvectors corresponding to the k largest eigenvalues of Σ. Then\nP[∥M(X) −Π∥≤α] ≥0.7.\n3\nThe sample complexity of our algorithm n = O(k log(1/δ)/ε) is independent of the ambient\ndimension d; this is ideal. However, there is a polynomial dependence on d in γ, which controls\nthe multiplicative eigenvalue gap. This multiplicative eigenvalue gap is a strong assumption,\nbut it is also a necessary assumption if we want the sample complexity n to be independent\nof the dimension d. In fact, it is necessary even without the differential privacy constraint [CZ16].\nThat is, if we did not assume an eigenvalue gap that depends polynomially on the ambient\ndimension d, then it would be impossible to estimate the subspace with sample complexity n\nthat is independent of the ambient dimension d even in the non-private setting.\nOur algorithm is based on the subsample and aggregate framework [NRS07] and a differ-\nentially private histogram algorithm. These methods are generally quite robust and thus our\nalgorithm is, too. For example, our algorithm can tolerate o(n/k) input points being corrupted\narbitrarily.\nWe also believe that our algorithm’s utility guarantee is robust to relaxing the\nGaussianity assumption. All that we require in the analysis is that the empirical covariance\nmatrix of a few samples from the distribution is sufﬁciently close to its expectation Σ with high\nprobability.\n1.3\nRelated Work\nTo the best of our knowledge, the problem of privately learning subspaces, as we formulate\nit, has not been studied before. However, a closely-related line of work is on Private Principal\nComponent Analysis (PCA) and low-rank approximations. We brieﬂy discuss this extensive\nline of work below, but ﬁrst we note that, in our setting, all of these techniques have a sample\ncomplexity n that grows polynomially with the ambient dimension d. Thus, they do not evade\nprivacy’s curse of dimensionality. However, we make a stronger assumption than these prior\nworks – namely, we assume a large multiplicative eigenvalue gap. (Many of the prior works\nconsider an additive eigenvalue gap, which is a weaker assumption.)\nThere has been a lot of interest in Private PCA, matrix completion, and low-rank approx-\nimation. One motivation for this is the infamous Netﬂix prize, which can be interpreted as a\nmatrix completion problem. The competition was cancelled after researchers showed that the\npublic training data revealed the private movie viewing histories of many of Netﬂix’s customers\n[NS06]. Thus privacy is a real concern for matrix analysis tasks.\nMany variants of these problems have been considered: Some provide approximations to the\ndata matrix X = (X1,··· ,Xn) ∈Rd×n; others approximate the covariance matrix A = Pn\ni XiXT\ni ∈\nRd×d (as we do). There are also different forms of approximation – we can either produce a\nsubspace or an approximation to the entire matrix, and the approximation can be measured by\ndifferent norms (we consider the operator norm between projection matrices). Importantly, we\ndeﬁne differential privacy to allow one data point Xi to be changed arbitrarily, whereas most\nof the prior work assumes a bound on the norm of the change or even assumes that only one\ncoordinate of one vector can be changed. In the discussion below we focus on the techniques\nthat have been considered for these problems, rather than the speciﬁc results and settings.\nDwork, Talwar, Thakurta, and Zhang [DTTZ14] consider the simple algorithm which adds\nindependent Gaussian noise to each of entries of the covariance matrix A, and then perform\nanalysis on the noisy matrix. (In fact, this algorithm predates the development of differential\n4\nprivacy [BDMN05] and was also analyzed under differential privacy by McSherry and Mironov\n[MM09] and Chaudhuri, Sarwate, and Sinha [CSS12].) This simple algorithm is versatile and\nseveral bounds are provided for the accuracy of the noisy PCA. The downside of this is that a\npolynomial dependence on the ambient dimension d is inherent – indeed, they prove a sample\ncomplexity lower bound of n = ˜Ω(\n√\nd) for any algorithm that identiﬁes a useful approximation\nto the top eigenvector of A. This lower bound does not contradict our results because the\nrelevant inputs do not satisfy our near low-rank assumption.\nHardt and Roth [HR12] and Arora, Braverman, and Upadhyay [ABU18] apply techniques\nfrom dimensionality reduction to privately compute a low-rank approximation to the input\nmatrix X. Hardt and Roth [HR13] and Hardt and Price [HP13] use the power iteration method\nwith noise injected at each step to compute low-rank approximations to the input matrix X. In\nall of these, the underlying privacy mechanism is still noise addition and the results still require\nthe sample complexity to grow polynomially with the ambient dimension to obtain interesting\nguarantees. (However, the results can be dimension-independent if we deﬁne differential\nprivacy so that only one entry – as opposed to one column – of the matrix X can be changed by\n1. This is a signiﬁcantly weaker privacy guarantee.)\nBlocki, Blum, Datta, and Sheffet [BBDS12] and Sheffet [She19] also use tools from dimen-\nsionality reduction; they approximate the covariance matrix A. However, they show that the\ndimensionality reduction step itself provides a privacy guarantee (whereas the aforementioned\nresults did not exploit this and relied on noise added at a later stage). Sheffet [She19] analyzes\ntwo additional techniques – the addition of Wishart noise (i.e., Y Y T where the columns of Y are\nindependent multivariate Gaussians) and sampling from an inverse Wishart distribution (which\nhas a Bayesian interpretation).\nChaudhuri, Sarwate, and Sinha [CSS12], Kapralov and Talwar [KT13], Wei, Sarwate, Coran-\nder, Hero, and Tarokh [WSCHT16], and Amin, Dick, Kulesza, Medina, and Vassilvitskii [AD-\nKMV18] apply variants of the exponential mechanism [MT07] to privately select a low-rank\napproximation to the covariance matrix A. This method is nontrivial to implement and analyse,\nbut it ultimately requires the sample complexity to grow polynomially in the ambient dimension.\nGonem and Gilad-Bachrach [GGB18] exploit smooth sensitivity [NRS07] to release a low-\nrank approximation to the matrix A. This allows adding less noise than worst case sensitivity,\nunder an eigenvalue gap assumption. However, the sample complexity n is polynomial in the\ndimension d.\nLimitations of Prior Work\nGiven the great variety of techniques and analyses that have been\napplied to differentially private matrix analysis problems, what is missing? We see that almost\nall of these techniques are ultimately based on some form of noise addition or the exponential\nmechanism. With the singular exception of the techniques of Sheffet [She19], all of these prior\ntechniques satisfy pure1 or concentrated differential privacy [BS16]. This is enough to conclude\nthat these techniques cannot yield the dimension-independent guarantees that we seek. No\namount of postprocessing or careful analysis can avoid this limitation. This is because pure and\nconcentrated differential privacy have strong group privacy properties, which means “packing”\nlower bounds [HT10] apply.\n1Pure differential privacy (a.k.a. pointwise differential privacy) is (ε,δ)-differential privacy with δ = 0.\n5\nWe brieﬂy sketch why concentrated differential privacy is incompatible with dimension-\nindependent guarantees. Let the input be X1 = X2 = ··· = Xn = ξ/\n√\nd for a uniformly random\nξ ∈{−1,+1}d. That is, the input is one random point repeated n times. If M satisﬁes O(1)-\nconcentrated differential privacy, then it satisﬁes the mutual information bound I(M(X);X) ≤\nO(n2) [BS16]. But, if M provides a meaningful approximation to X or A = XXT , then we must be\nable to recover an approximation to ξ from its output, whence I(M(X);X) ≥Ω(d), as the entropy\nof X is d bits. This gives a lower bound of n ≥Ω(\n√\nd), even though X and A have rank k = 1.\nThe above example shows that, even under the strongest assumptions (i.e., the data lies\nexactly in a rank-1 subspace), any good approximation to the subspace, to the data matrix X, or\nto the covariance matrix A = XXT must require the sample complexity n to grow polynomially\nin the ambient dimension d if we restrict to techniques that satisfy concentrated differential\nprivacy. Almost all of the prior work in this general area is subject to this restriction.\nTo avoid a sample complexity n that grows polynomially with the ambient dimension d, we\nneed fundamentally new techniques.\n1.4\nOur Techniques\nFor the exact case, we construct a score function for subspaces that has low sensitivity, assigns\nhigh score to the correct subspace, and assigns a low score to all other subspaces. Then we can\nsimply apply a GAP-MAX algorithm to privately select the correct subspace [BDRS18].\nThe GAP-MAX algorithm satisﬁes (ε,δ)-differential privacy and outputs the correct subspace\nas long as the gap between its score and that of any other subspace is larger than O(log(1/δ)/ε).\nThis works even though there are inﬁnitely many subspaces to consider, which would not be\npossible under concentrated differential privacy.\nThe simplest score function would simply be the number of input points that the subspace\ncontains. This assigns high score to the correct subspace, but it also assigns high score to any\nlarger subspace that contains the correct subspace. To remedy this, we subtract from the score\nthe number of points contained in a strictly smaller subspace. That is, the score of subspace S\nis the number of points in S minus the maximum over all subspaces S′ ⊊S of the number of\npoints contained in S′.\nThis GAP-MAX approach easily solves the exact case, but it does not readily extend to the\napproximate case. If we count points near to the subspace, rather than in it, then (inﬁnitely)\nmany subspaces will have high score, which violates the assumptions needed for GAP-MAX to\nwork. Thus we use a completely different approach for the approximate case.\nWe apply the “subsample and aggregate” paradigm of [NRS07]. That is, we split the dataset\nX1,··· ,Xn into n/O(k) sub-datasets each of size O(k). We use each sub-dataset to compute an\napproximation to the subspace by doing a (non-private) PCA on the sub-dataset. Let Π be\nthe projection matrix onto the correct subspace and Π1,··· ,Πn/O(k) the projection matrices onto\nthe approximations derived from the sub-datasets. With high probability ∥Πj −Π∥is small for\nmost j. (Exactly how small depends on the eigengap.) Now we must privately aggregate the\nprojection matrices Π1,··· ,Πn/O(k) into a single projection matrix.\nRather than directly trying to aggregate the projection matrices, we pick a set of reference\npoints, project them onto the subspaces, and then aggregate the projected points. We draw\n6\np1,··· ,pO(k) independently from a standard spherical Gaussian. Then ∥Πjpi −Πpi∥≤∥Πj −Π∥·\nO(\n√\nk) is also small for all i and most j. We wish to privately approximate Πpi and to do this\nwe have n/O(k) points Πjpi most of which are close to Πpi. This is now a location or mean\nestimation problem, which we can solve privately. Thus we obtain points ˆpi such that ∥ˆpi −Πpi∥\nis small for all i. From a PCA of these points we can obtain a projection ˆΠ with ∥ˆΠ −Π∥being\nsmall, as required.\nFinally, we discuss how to privately obtain ( ˆp1, ˆp2,··· , ˆpO(k)) from (Π1p1,··· ,Π1pO(k)),··· ,\n(Πn/O(k)p1,··· ,Πn/O(k)pO(k)). It is better here to treat ( ˆp1, ˆp2,··· , ˆpO(k)) as a single vector in RO(kd),\nrather than as O(k) vectors in Rd. We split RO(kd) into cells and then run a differentially\nprivate histogram algorithm. If we construct the cells carefully, for most j we have that\n(Πjp1,··· ,ΠjpO(k)) is in the same histogram cell as the desired point (Πp1,··· ,ΠpO(k)). The\nhistogram algorithm will thus identify this cell, and we take an arbitrary point from this cell as\nour estimate ( ˆp1, ˆp2,··· , ˆpO(k)). The differentially private histogram algorithm is run over expo-\nnentially many cells, which is possible under (ε,δ)-differential privacy if n/O(k) ≥O(log(1/δ)/ε).\n(Note that under concentrated differential privacy the histogram algorithm’s sample complexity\nn would need to depend on the number of cells and, hence, the ambient dimension d.)\nThe main technical ingredients in the analysis of our algorithm for the approximate case\nare matrix perturbation and concentration analysis and the location estimation procedure\nusing differentially private histograms. Our matrix perturbation analysis uses a variant of\nthe Davis-Kahan theorem to show that if the empirical covariance matrix is close to the true\ncovariance matrix, then the subspaces corresponding to the top k eigenvalues of each are also\nclose; this is applied to both the subsamples and the projection of the reference points. The\nmatrix concentration results that we use show that the empirical covariance matrices in all the\nsubsamples are close to the true covariance matrix. This is the only place where the multivariate\nGaussian assumption arises. Any distribution that concentrates well will work.\n2\nNotations, Deﬁnitions, and Background Results\n2.1\nLinear Algebra and Probability Preliminaries\nHere, we mention a few key technical results that we will be using to prove the main theorem\nfor the approximate case. Throughout this document, we assume that the dimension d is\nlarger than some absolute constant, and adopt the following notation: for a matrix A of rank\nr, we use s1(A) ≥··· ≥sr(A) to denote the singular values of A in decreasing order, and use\nλ1(A) ≥··· ≥λr(A) to denote the eigenvalues of A in decreasing order; let smin(A) denote the\nleast, non-zero singular value of A. We omit the parentheses when the context is clear. We begin\nby stating two results about matrix perturbation theory. The ﬁrst result says that if two matrices\nare close to one another in operator norm, then their corresponding singular values are also\nclose to one another.\nDeﬁne\n∥M∥:= sup{∥Mx∥2 : x ∈Rd, ∥x∥2 ≤1}\nto be the operator norm with respect to the Euclidean vector norm.\n7\nLemma 2.1 (Singular Value Inequality). Let A,B ∈Rd×n and let r = min{d,n}. Then for 1 ≤i,j ≤r,\nsi+j−1(A + B) ≤si(A) + sj(B).\nThe following result gives a lower bound on the least singular value of sum of two matrices.\nLemma 2.2 (Least Singular Value of Matrix Sum). Let A,B ∈Rd×n. Then\nsmin(A + B) ≥smin(A) −∥B∥.\nThe next result bounds the angle between the subspaces spanned by two matrices that are\nclose to one another. Let X ∈Rd×n have the following SVD.\nX =\nh\nU\nU⊥\ni\n·\n\"\nΣ1\n0\n0\nΣ2\n#\n·\n\"\nV T\nV T\n⊥\n#\nIn the above, U,U⊥are orthonormal matrices such that U ∈Rd×r and U⊥∈Rd×(d−r), Σ1,Σ2 are\ndiagonal matrices, such that Σ1 ∈Rr×r and Σ2 ∈R(d−r)×(n−r), and V ,V⊥are orthonormal matrices,\nsuch that V ∈Rn×r and V⊥∈Rn×(n−r). Let Z ∈Rd×n be a perturbation matrix, and ˆX = X + Z,\nsuch that ˆX has the following SVD.\nˆX =\nh ˆU\nˆU⊥\ni\n·\n\" ˆΣ1\n0\n0\nˆΣ2\n#\n·\n\" ˆV T\nˆV T\n⊥\n#\nIn the above, ˆU, ˆU⊥, ˆΣ1, ˆΣ2, ˆV , ˆV⊥have the same structures as U,U⊥,Σ1,Σ2,V ,V⊥respectively.\nLet Z21 = U⊥UT\n⊥ZV V T and Z12 = UUT ZV⊥V T\n⊥. Suppose σ1 ≥··· ≥σr ≥0 are the singular\nvalues of UT ˆU. Let Θ(U, ˆU) ∈Rr×r be a diagonal matrix, such that Θii(U, ˆU) = cos−1(σi).\nLemma 2.3 (Sin(Θ) Theorem [CZ16]). Let X, ˆX,Z,Z12,Z21 be deﬁned as above. Denote α = smin(UT ˆXV )\nand β = ∥UT\n⊥ˆXV⊥∥. If α2 > β2 + min{∥Z12∥2,∥Z21∥2}, then we have the following.\n∥Sin(Θ)(U, ˆU)∥≤\nα∥Z21∥+ β∥Z12∥\nα2 −β2 −min{∥Z12∥2,∥Z21∥2}\nThe next result bounds ∥Sin(Θ)(U, ˆU)∥in terms of the distance between UUT and ˆU ˆUT .\nLemma 2.4 (Property of ∥Sin(Θ)∥[CZ16]). Let U, ˆU ∈Rd×r be orthonormal matrices, and let Θ(U, ˆU)\nbe deﬁned as above in terms of ˆU,U. Then we have the following.\n∥Sin(Θ)(U, ˆU)∥≤∥ˆU ˆUT −UUT ∥≤2∥Sin(Θ)(U, ˆU)∥\nThe next result bounds the singular values of a matrix, whose columns are independent\nvectors from a mean zero, isotropic distribution in Rd. We ﬁrst deﬁne the sub-Gaussian norm of\na random variable.\nDeﬁnition 2.5. Let X be a sub-Gaussian random variable. The sub-Gaussian norm of X, denoted\nby ∥X∥ψ2, is deﬁned as,\n∥X∥ψ2 = inf{t > 0 : E\nh\nexp(X2/t2)\ni\n≤2}.\n8\nLemma 2.6 (Theorem 4.6.1 [Ver18]). Let A be an n × m matrix, whose columns Ai are independent,\nmean zero, sub-Gaussian isotropic random vectors in Rn. Then for any t ≥0, we have\n√\nm −CK2(\n√\nn + t) ≤sn(A) ≤s1(A) ≤\n√\nm + CK2(\n√\nn + t)\nwith probability at least 1 −2exp(−t2). Here, K = maxi ∥A∥ψ2 (sub-Gaussian norm of A).\nIn the above, ∥A∥ψ2 ∈O(1) if the distribution in question is N (⃗0,I). The following corollary\ngeneralises the above result for arbitrary Gaussians.\nCorollary 2.7. Let A be an n × m matrix, whose columns Ai are independent, random vectors in Rn\nfrom N (⃗0,Σ). Then for any t ≥0, we have\n(\n√\nm −CK2(\n√\nn + t))\np\nsn(Σ) ≤sn(A) ≤(\n√\nm + CK2(\n√\nn + t))\np\nsn(Σ)\nand\ns1(A) ≤(\n√\nm + CK2(\n√\nn + t))\np\ns1(Σ)\nwith probability at least 1 −2exp(−t2). Here, K = maxi ∥A∥ψ2 (sub-Gaussian norm of A).\nProof. First, we prove the lower bound on sn(A). Note that sn(A) = min\n∥x∥>0\n∥Ax∥\n∥x∥, and that the\ncolumns of Σ−1\n2 A are distributed as N (⃗0,I). Therefore, we have the following.\nmin\n∥x∥>0\n∥Ax∥\n∥x∥= min\n∥x∥>0\n∥Σ\n1\n2 Σ−1\n2 Ax∥\n∥x∥\n= min\n∥x∥>0\n∥Σ\n1\n2 Σ−1\n2 Ax∥\n∥Σ−1\n2 Ax∥\n∥Σ−1\n2 Ax∥\n∥x∥\n≥min\n∥x∥>0\n∥Σ\n1\n2 Σ−1\n2 Ax∥\n∥Σ−1\n2 Ax∥\nmin\n∥x∥>0\n∥Σ−1\n2 Ax∥\n∥x∥\n≥min\n∥y∥>0\n∥Σ\n1\n2 y∥\n∥y∥\nmin\n∥x∥>0\n∥Σ−1\n2 Ax∥\n∥x∥\n≥(\n√\nm −CK2(\n√\nn + t))\np\nsn(Σ)\n(Lemma 2.6)\nNext, we prove the upper bound on sn(A). For this, we ﬁrst show that for X ∈Rm×d and Y ∈Rd×n,\nsmin(XY ) ≤smin(X) · ∥Y ∥.\nsmin(XY ) = min\n∥z∥=1∥XY z∥\n≤min\n∥z∥=1∥X∥∥Y z∥\n= ∥X∥· min\n∥z∥=1∥Y z∥\n= ∥X∥· smin(Y )\nNow, smin(XY ) = smin(Y T XT ) ≤∥Y ∥·smin(X) by the above reasoning. Using this results, we have\nthe following.\nsn(A) = sn(Σ1/2 · Σ−1/2A)\n9\n≤sn(Σ1/2)∥Σ−1/2A∥\n≤(\n√\nm + CK2(\n√\nn + t))\np\nsn(Σ)\n(Lemma 2.6)\nNow, we show the upper bound on s1(A). Note that s1(A) = ∥A∥.\n∥A∥= ∥Σ\n1\n2 Σ−1\n2 A∥\n≤∥Σ\n1\n2 ∥· ∥Σ−1\n2 A∥\n≤(\n√\nm + CK2(\n√\nn + t))\np\ns1(Σ)\n(Lemma 2.6)\nThis completes the proof.\nNow, we state a concentration inequality for χ2 random variables.\nLemma 2.8. Let X be a χ2 random variable with k degrees of freedom. Then,\nP\nh\nX > k + 2\n√\nkt + 2t\ni\n≤e−t.\nNext, we state the well-known Bernstein’s inequality for sums of independent Bernoulli\nrandom variables.\nLemma 2.9 (Bernstein’s Inequality). Let X1,...,Xm be independent Bernoulli random variables taking\nvalues in {0,1}. Let p = E[Xi]. Then for m ≥5p\n2ε2 ln(2/β) and ε ≤p/4,\nP\n\u0014\f\f\f\f\f\n1\nm\nX\nXi −p\n\f\f\f\f\f ≥ε\n\u0015\n≤2e−ε2m/2(p+ε) ≤β.\nWe ﬁnally state a result about the norm of a vector sampled from N (⃗0,I).\nLemma 2.10. Let X1,...,Xq ∼N (⃗0,Σ) be vectors in Rd, where Σ is the projection of Id×d on to a\nsubspace of Rd of rank k. Then\nP\nh\n∀i,∥Xi∥2 ≤k + 2\n√\nkt + 2t\ni\n≥1 −qe−t.\nProof. Since Σ is of rank k, we can directly use Lemma 2.8 for a ﬁxed i ∈[q], and the union\nbound over all i ∈[q] to get the required result. This is because for any i, ∥Xi∥2 is a χ2 random\nvariable with k degrees of freedom.\n2.2\nPrivacy Preliminaries\nDeﬁnition 2.11 (Differential Privacy (DP) [DMNS06]). A randomized algorithm M : X n →Y\nsatisﬁes (ε,δ)-differential privacy ((ε,δ)-DP) if for every pair of neighboring datasets X,X′ ∈X n\n(i.e., datasets that differ in exactly one entry),\n∀Y ⊆Y\nP[M(X) ∈Y ] ≤eε · P\u0002M(X′) ∈Y \u0003 + δ.\nWhen δ = 0, we say that M satisﬁes ε-differential privacy or pure differential privacy.\n10\nNeighbouring datasets are those that differ by the replacement of one individual’s data.\nIn our setting, each individual’s data is assumed to correspond to one point in X = Rd, so\nneighbouring means one point is changed arbitrarily.\nThroughout the document, we will assume that ε is smaller than some absolute constant less\nthan 1 for notational convenience, but note that our results still hold for general ε. Now, this\nprivacy deﬁnition is closed under post-processing.\nLemma 2.12 (Post Processing [DMNS06]). If M : X n →Y is (ε,δ)-DP, and P : Y →Z is any\nrandomized function, then the algorithm P ◦M is (ε,δ)-DP.\n2.3\nBasic Differentially Private Mechanisms.\nWe ﬁrst state standard results on achieving privacy via noise addition proportional to\nsensitivity [DMNS06].\nDeﬁnition 2.13 (Sensitivity). Let f : X n →Rd be a function, its ℓ1-sensitivity and ℓ2-sensitivity\nare\n∆f ,1 =\nmax\nX∼X′∈X n ∥f (X) −f (X′)∥1\nand\n∆f ,2 =\nmax\nX∼X′∈X n ∥f (X) −f (X′)∥2,\nrespectively. Here, X ∼X′ denotes that X and X′ are neighboring datasets (i.e., those that differ\nin exactly one entry).\nOne way of introducing (ε,δ)-differential privacy is via adding noise sampled from the\ntruncated Laplace distribution, proportional to the ℓ1 sensitivity.\nLemma 2.14 (Truncated Laplace Mechanism [GDGK20]). Deﬁne the probability density function\n(p) of the truncated Laplace distribution as follows.\np(x) =\n\nBe−|x|\nλ\nif x ∈[−A,A]\n0\notherwise\nIn the above,\nλ = ∆\nε ,\nA = ∆\nε log\n \n1 + eε −1\n2δ\n!\n,\nB =\n1\n2λ(1 −e−A\nλ )\n.\nLet TLap(∆,ε,δ) denote a draw from the above distribution.\nLet f : X n →Rd be a function with sensitivity ∆. Then the truncated Laplace mechanism\nM(X) = f (X) + TLap(∆,ε,δ)\nsatisﬁes (ε,δ)-DP.\nIn the above A ≤\n∆f ,1\nε log(1/δ) since ε is smaller than some absolute constant less than 1. Now,\nwe introduce differentially private histograms.\nLemma 2.15 (Private Histograms). Let n ∈N, ε,δ,β > 0, and X a set. There exists M : X n →RX\nwhich is (ε,δ)-differentially private and, for all x ∈X n, we have\nP\nM\n\nsup\ny∈X\n\f\f\f\f\fM(x)y −1\nn|{i ∈[n] : xi = y}|\n\f\f\f\f\f ≤O\n log(1/δβ)\nεn\n!\n≥1 −β.\n11\nThe above holds due to [BNS16; Vad17]. Finally, we introduce the GAP-MAX algorithm from\n[BDRS18] that outputs the element from the output space that has the highest score function,\ngiven that there is a signiﬁcant gap between the scores of the highest and the second to the\nhighest elements.\nLemma 2.16 (GAP-MAX Algorithm [BDRS18]). Let SCORE : X n × Y →R be a score function with\nsensitivity 1 in its ﬁrst argument, and let ε,δ > 0. Then there exists a (ε,δ)-differentially private\nalgorithm M : X n →Y and α = Θ(log(1/δ)/εn) with the following property. Fix an input X ∈X n. Let\ny∗= argmax\ny∈Y\n{SCORE(X,y)}.\nSuppose\n∀y ∈Y,y , y∗=⇒SCORE(X,y) < SCORE(X,y∗) −αn.\nThen M outputs y∗with probability 1.\n3\nExact case\nHere, we discuss the case, where all n points lie exactly in a subspace s∗of dimension k of\nRd. Our goal is to privately output that subspace. We do it under the assumption that all strict\nsubspaces of s∗contain at most ℓpoints. If the points are in general position, then ℓ= k−1, as any\nstrictly smaller subspace has dimension < k and cannot contain more points than its dimension.\nLet Sk\nd be the set of all k-dimensional subspaces of Rd. Let Sd be the set of all subspaces of Rd.\nWe formally deﬁne that problem as follows.\nProblem 3.1. Assume (i) all but at most ℓ, input points are in some s∗∈Sk\nd, and (ii) every\nsubspace of dimension < k contains at most ℓpoints. (If the points are in general position – aside\nfrom being contained in s∗– then ℓ= k −1.) The goal is to output a representation of s∗.\nWe call these ≤ℓpoints that do not lie in s∗, “adversarial points”. With the problem deﬁned\nin Problem 3.1, we will state the main theorem of this section.\nTheorem 3.2. For any ε,δ > 0, ℓ≥k −1 ≥0, and\nn ≥O\n \nℓ+ log(1/δ)\nε\n!\n,\nthere exists an (ε,δ)-DP algorithm M : Rd×n →Sk\nd, such that if X is a dataset of n points satisfying the\nconditions in Problem 3.1, then M(X) outputs a representation of s∗with probability 1.\nWe prove Theorem 3.2 by proving the privacy and the accuracy guarantees of Algorithm 1.\nThe algorithm performs a GAP-MAX (cf. Lemma 2.16). It assigns a score to all the relevant\nsubspaces, that is, the subspaces spanned by the points of the dataset X. We show that the only\nsubspace that has a high score is the true subspace s∗, and the rest of the subspaces have low\nscores. Then GAP-MAX outputs the true subspace successfully because of the gap between the\nscores of the best subspace and the second to the best one. For GAP-MAX to work all the time,\n12\nwe deﬁne a default option in the output space that has a high score, which we call NULL. Thus,\nthe output space is now Y = Sd ∪{NULL}. Also, for GAP-MAX to run in ﬁnite time, we ﬁlter Sd\nto select ﬁnite number of subspaces that have at least 0 scores on the basis of X. Note that this is\na preprocessing step, and does not violate privacy as, we will show, all other subspaces already\nhave 0 probability of getting output. We deﬁne the score function u : X n × Y →N as follows.\nu(x,s) :=\n\n|x ∩s| −sup{|x ∩t| : t ∈Sd,t ⊊s}\nif s ∈Sd\nℓ+ 4log(1/δ)\nε\n+ 1\nif s = NULL\nNote that this score function can be computed in ﬁnite time because for any m points and i > 0,\nif the points are contained in an i-dimensional subspace, then the subspace that contains all m\npoints must lie within the set of subspaces spanned by \u0000 m\ni+1\n\u0001 subsets of points.\nAlgorithm 1: DP Exact Subspace Estimator DPESEε,δ,k,ℓ(X)\nInput: Samples X ∈Rd×n. Parameters ε,δ,k,ℓ> 0.\nOutput: ˆs ∈Sk\nd.\nSet Y ←{NULL} and sample noise ξ(NULL) from TLap(2,ε,δ).\nSet score u(X,NULL) = ℓ+ 4log(1/δ)\nε\n+ 1.\n// Identify candidate outputs.\nFor each subset S of X of size k\nLet s be the subspace spanned by S.\nY ←Y ∪{s}.\nSample noise ξ(s) from TLap(2,ε,δ).\nSet score u(X,s) = |x ∩s| −sup{|x ∩t| : t ∈Sd,t ⊊s}.\n// Apply GAP-MAX.\nLet s1 = argmaxs∈Y u(X,s) be the candidate with the largest score.\nLet s2 = argmaxs∈Y\\{s1} u(X,s) be the candidate with the second-largest score.\nLet ˆs = argmaxs∈Y max{0,u(X,s) −u(X,s2) −1} + ξ(s).\n// Truncated Laplace noise ξ ∼TLap(2,ε,δ); see Lemma 2.14\nReturn ˆs.\nWe split the proof of Theorem 1.1 into sections for privacy (Lemma 3.3) and accuracy\n(Lemma 3.5).\n3.1\nPrivacy\nLemma 3.3. Algorithm 1 is (ε,δ)-differentially private.\nThe proof of Lemma 3.3 closely follows the privacy analysis of GAP-MAX by [BDRS18]. The\nonly novelty is that Algorithm 1 may output NULL in the case that the input is malformed (i.e.,\ndoesn’t satisfy the assumptions of Problem 3.1).\nThe key is that the score u(X,s) is low sensitivity. Thus max{0,u(X,s) −u(X,s2) −1} also\nhas low sensitivity. What we gain from subtracting the second-largest score and taking this\n13\nmaximum is that these values are also sparse – only one (s = s1) is nonzero. This means we can\nadd noise to all the values without paying for composition. We now prove Lemma 3.3.\nProof. First, we argue that the sensitivity of u is 1. The quantity |X ∩s| has sensitivity 1 and so\ndoes sup{|X ∩t| : t ∈Sd,t ⊊s}. This implies sensitivity 2 by the triangle inequality. However, we\nsee that it is not possible to change one point that simultaneously increases |X ∩s| and decreases\nsup{|X ∩t| : t ∈Sd,t ⊊s} or vice versa. Thus the sensitivity is actually 1.\nWe also argue that u(X,s2) has sensitivity 1, where s2 is the candidate with the second-largest\nscore. Observe that the second-largest score is a monotone function of the collection of all scores\n– i.e., increasing scores cannot decrease the second-largest score and vice versa. Changing one\ninput point can at most increase all the scores by 1, which would only increase the second-largest\nscore by 1.\nThis implies that max{0,u(X,s) −u(X,s2) −1} has sensitivity 2 by the triangle inequality and\nthe fact that the maximum does not increase the sensitivity.\nNow we observe that for any input X there is at most one s such that max{0,u(X,s)−u(X,s2)−\n1} , 0, namely s = s1. We can say something even stronger: Let X and X′ be neighbouring\ndatasets with s1 and s2 the largest and second-largest scores on X and s′\n1 and s′\n2 the largest and\nsecond-largest scores on X′. Then there is at most one s such that max{0,u(X,s)−u(X,s2)−1} , 0\nor max{0,u(X′,s) −u(X′,s′\n2) −1} , 0. In other words, we cannot have both u(X,s1) −u(X,s2) > 1\nand u(X′,s′\n1) −u(X′,s′\n2) > 1 unless s1 = s′\n1. This holds because u(X,s) −u(X,s2) has sensitivity 2.\nWith these observations in hand, we can delve into the privacy analysis. Let X and X′ be\nneighbouring datasets with s1 and s2 the largest and second-largest scores on X and s′\n1 and s′\n2\nthe largest and second-largest scores on X′. Let Y be the set of candidates from X and let Y′ be\nthe set of candidates from X′. Let ˇY = Y ∪Y′ and ˆY = Y ∩Y′.\nWe note that, for s ∈ˇY, if u(X,s) ≤ℓ, then there is no way that ˆs = s. This is because\n|ξ(s)| ≤2log(1/δ)\nε\nfor all s and hence, there is no way we could have argmaxs∈Y max{0,u(X,s) −\nu(X,s2) −1} + ξ(s) ≥argmaxs∈Y max{0,u(X,NULL) −u(X,s2) −1} + ξ(NULL).\nIf s ∈ˇY \\ ˆY, then u(X,s) ≤|X ∩s| ≤k + 1 ≤ℓand u(X′,s) ≤ℓ. This is because s < ˆY implies\n|X ∩s| < k or |X′ ∩s| < k, but |X ∩s| ≤|X′ ∩s| + 1. Thus, there is no way these points are output\nand, hence, we can ignore these points in the privacy analysis. (This is the reason for adding the\nNULL candidate.)\nNow we argue that the entire collection of noisy values max{0,u(X,s) −u(X,s2) −1} + ξ(s)\nfor s ∈ˆY is differentially private. This is because we are adding noise to a vector where (i) on\nthe neighbouring datasets only 1 coordinate is potentially different and (ii) this coordinate has\nsensitivity 2.\n3.2\nAccuracy\nWe start by showing that the true subspace s∗has a high score, while the rest of the subspaces\nhave low scores.\nLemma 3.4. Under the assumptions of Problem 3.1, u(x,s∗) ≥n −2ℓand u(x,s′) ≤2ℓfor s′ , s∗.\nProof. We have u(x,s∗) = |x ∩s∗| −|x ∩s′| for some s′ ∈Sd with s′ ⊊s∗. The dimension of s′ is at\nmost k −1 and, by the assumption (ii), |x ∩s′| ≤ℓ.\n14\nLet s′ ∈Sd \\ {s∗}. There are three cases to analyse:\n1. Let s′ ⊋s∗. Then u(x,s′) ≤|x ∩s′| −|x ∩s∗| ≤ℓbecause the ≤ℓadverserial points and the\n≥n −ℓnon-adversarial points may not together lie in a subspace of dimension k.\n2. Let s′ ⊊s∗. Let k′ be the dimension of s′. Clearly k′ < k. By our assumption (ii), |s′ ∩x| ≤ℓ.\nThen u(x,s′) = |x∩s′|−|x∩t| ≤ℓfor some t because the ≤ℓadversarial points already don’t\nlie in s∗, so they will not lie in any subspace of s∗.\n3. Let s′ be incomparable to s∗. Let s′′ = s′ ∩s∗. Then u(x,s′) ≤|x ∩s′| −|x ∩s′′| ≤ℓbecause the\nadversarial points may not lie in s∗, but could be in s′ \\ s′′.\nThis completes the proof.\nNow, we show that the algorithm is accurate.\nLemma 3.5. If n ≥3ℓ+ 8log(1/δ)\nε\n+ 2, then Algorithm 1 outputs s∗for Problem 3.1.\nProof. From Lemma 3.4, we know that s∗has a score of at least n−2ℓ, and the next best subspace\ncan have a score of at most ℓ. Also, the score of NULL is deﬁned to be ℓ+ 4log(1/δ)\nε\n+ 1. This\nmeans that the gap satisﬁes max{0,u(X,s∗)−u(X,s2)−1} ≥n−3ℓ−4log(1/δ)\nε\n−1. Since the noise is\nbounded by 2log(1/δ)\nε\n, our bound on n implies that ˆs = s∗\n3.3\nLower Bound\nHere, we show that our upper bound is optimal up to constants for the exact case.\nTheorem 3.6. Any (ε,δ)-DP algorithm that takes a dataset of n points satisfying the conditions in\nProblem 3.1 and outputs s∗with probability > 0.5 requires n ≥Ω\n\u0010\nℓ+ log(1/δ)\nε\n\u0011\n.\nProof. First, n ≥ℓ+k. This is because we need at least k points to span the subspace, and ℓpoints\ncould be corrupted. Second, n ≥Ω(log(1/δ)/ε) by group privacy. Otherwise, the algorithm\nis (10,0.1)-differentially private with respect to changing the entire dataset and it is clearly\nimpossible to output the subspace under this condition.\n4\nApproximate Case\nIn this section, we discuss the case, where the data “approximately” lies in a k-dimensional\nsubspace of Rd. We make a Gaussian distributional assumption, where the covariance is\napproximately k-dimensional, though the results could be extended to distributions with heavier\ntails using the right inequalities. We formally deﬁne the problem:\nProblem 4.1. Let Σ ∈Rd×d be a symmetric, PSD matrix of rank ≥k ∈{1,...,d}, and let 0 < γ ≪1,\nsuch that λk+1\nλk ≤γ2. Suppose Π is the projection matrix corresponding to the subspace spanned\nby the eigenvectors of Σ corresponding to the eigenvalues λ1,...,λk. Given sample access to\nN (⃗0,Σ), and 0 < α < 1, output a projection matrix bΠ, such that ∥Π −bΠ∥≤α.\n15\nWe solve Problem 4.1 under the constraint of (ε,δ)-differential privacy. Throughout this\nsection, we would refer to the subspace spanned by the top k eigenvectors of Σ as the “true” or\n“actual” subspace.\nAlgorithm 2 solves Problem 4.1 and proves Theorem 1.2. Here ∥· ∥is the operator norm.\nRemark 4.2. We scale the eigenvalues of Σ so that λk = 1 and λk+1 ≤γ2. Also, for the purpose\nof the analysis, we will be splitting Σ = Σk + Σd−k, where Σk is the covariance matrix formed by\nthe top k eigenvalues and the corresponding eigenvectors of Σ and Σd−k is remainder.\nAlso, we assume the knowledge of γ (or an upper bound on γ). Our solution is presented in\nAlgorithm 2. The following theorem is the main result of the section.\nTheorem 4.3. Let Σ ∈Rd×d be an arbitrary, symmetric, PSD matrix of rank ≥k ∈{1,...,d}, and let\n0 < γ < 1. Suppose Π is the projection matrix corresponding to the subspace spanned by the vectors of\nΣk. Then given\nγ2 ∈O\n \nεα2n\nd2k ln(1/δ) · min\n(1\nk ,\n1\nln(k ln(1/δ)/ε)\n)!\n,\nsuch that λk+1(Σ) ≤γ2λk(Σ), for every ε,δ > 0, and 0 < α < 1, there exists and (ε,δ)-DP algorithm that\ntakes\nn ≥O\n k log(1/δ)\nε\n+ log(1/δ)log(log(1/δ)/ε)\nε\n!\nsamples from N (⃗0,Σ), and outputs a projection matrix bΠ, such that ∥Π −bΠ∥≤α with probability at\nleast 0.7.\nAlgorithm 2 is a type of “Subsample-and-Aggregate” algorithm [NRS07]. Here, we consider\nmultiple subspaces formed by the points from the same Gaussian, and privately ﬁnd a subspace\nthat is close to all those subspaces. Since the subspaces formed by the points would be close to\nthe true subspace, the privately found subspace would be close to the true subspace.\nA little more formally, we ﬁrst sample q public data points (called “reference points”) from\nN (⃗0,I). Next, we divide the original dataset X into disjoint datasets of m samples each, and\nproject all reference points on the subspaces spanned by every subset. Now, for every reference\npoint, we do the following. We have t = n\nm projections of the reference point. Using DP histogram\nover Rd, we aggregate those projections in the histogram cells; with high probability all those\nprojections will be close to one another, so they would lie within one histogram cell. We output\na random point from the histogram cell corresponding to the reference point. With a total of q\npoints output in this way, we ﬁnally output the projection matrix spanned by these points. In\nthe algorithm C0, C1, and C2 are universal constants.\nWe divide the proof of Theorem 4.3 into two parts: privacy (Lemma 4.4) and accuracy\n(Lemma 4.9).\n4.1\nPrivacy\nWe analyse the privacy by understanding the sensitivities at the only sequence of steps invok-\ning a differentially private mechanism, that is, the sequence of steps involving DP-histograms.\n16\nAlgorithm 2: DP Approximate Subspace Estimator DPASEε,δ,α,γ,k(X)\nInput: Samples X1,...,Xn ∈Rd. Parameters ε,δ,α,γ,k > 0.\nOutput: Projection matrix bΠ ∈Rd×d of rank k.\nSet parameters: t ←C0 ln(1/δ)\nε\nm ←⌊n/t⌋\nq ←C1k\nℓ←\nC2γ\n√\ndk(\n√\nk+√\nln(kt))\n√m\nSample reference points p1,...,pq from N (⃗0,I) independently.\n// Subsample from X, and form projection matrices.\nFor j ∈1,...,t\nLet Xj = (X(j−1)m+1,...,Xjm) ∈Rd×m.\nLet Πj ∈Rd×d be the projection matrix onto the subspace spanned by the\neigenvectors of Xj(Xj)T ∈Rd×d corresponding to the largest k eigenvalues.\nFor i ∈1,...,q\npj\ni ←Πjpi\n// Create histogram cells with random offset.\nLet λ be a random number in [0,1).\nDivide Rqd into Ω= {...,[λℓ+ iℓ,λℓ+ (i + 1)ℓ),...}qd, for all i ∈Z.\nLet each disjoint cell of length ℓbe a histogram bucket.\n// Perform private aggregation of subspaces.\nFor each i ∈[q], let Qi ∈Rd×t be the dataset, where column j is pj\ni.\nLet Q ∈Rqd×t be the vertical concatenation of all Qi’s in order.\nRun (ε,δ)-DP histogram over Ωusing Q to get ω ∈Ωthat contains at least t\n2 points.\nIf no such ω exists\nReturn ⊥\n// Return the subspace.\nLet bp = (bp1,...,bpd,...,bp(q−1)d+1,...,bpqd) be a random point in ω.\nFor each i ∈[q]\nLet bpi = (bp(i−1)d+1,...,bpid).\nLet bΠ be the projection matrix of the top-k subspace of (bp1,...,bpq).\nReturn bΠ.\nLemma 4.4. Algorithm 2 is (ε,δ)-differentially private.\nProof. Changing one point in X can change only one of the Xj’s. This can only change one\npoint in Q, which in turn can only change the counts in two histogram cells by 1. Therefore,\nthe sensitivity is 2. Because the sensitivity of the histogram step is bounded by 2 (Lemma 4.4),\nan application of DP-histogram, by Lemma 2.15, is (ε,δ)-DP. Outputting a random point in the\nprivately found histogram cell preserves privacy by post-processing (Lemma 2.12). Hence, the\nclaim.\n17\n4.2\nAccuracy\nNow we delve into the utility analysis of the algorithm. For 1 ≤j ≤t, let Xj be the subsets of\nX as deﬁned in Algorithm 2, and Πj be the projection matrices of their respective subspaces. We\nnow show that Πj and the projection matrix of the subspace spanned by Σk are close in operator\nnorm.\nLemma 4.5. Let Π be the projection matrix of the subspace spanned by the vectors of Σk, and for each\n1 ≤j ≤t, let Πj be the projection matrix as deﬁned in Algorithm 2. If m ≥O(k + ln(qt)), then\nP\n\n∀j,∥Π −Πj∥≤O\n\n\nγ\n√\nd\n√m\n\n\n\n≥0.95\nProof. We show that the subspaces spanned by Xj and the true subspace spanned by Σ are\nclose. Formally, we invoke Lemmata 2.3 and 2.4. This closeness follows from standard matrix\nconcentration inequalities.\nFix a j ∈[t]. Note that Xj can be written as Y j + H, where Y j is the matrix of vectors\ndistributed as N (⃗0,Σk), and H is a matrix of vectors distributed as N (⃗0,Σd−k), where Σk and\nΣd−k are deﬁned as in Remark 4.2. By Corollary 2.7, with probability at least 1 −0.02\nt , sk(Y j) ∈\nΘ((√m +\n√\nk)(\np\nsk(Σk))) = Θ(√m +\n√\nk) > 0. Therefore, the subspace spanned by Y j is the same as\nthe subspace spanned by Σk. So, it sufﬁces to look at the subspace spanned by Y j.\nNow, by Corollary 2.7, we know that with probability at least 1 −0.02\nt , ∥Xj −Y j∥= ∥H∥≤\nO((√m +\n√\nd)\np\ns1(Σd−k)) ≤O(γ(√m +\n√\nd)\np\nsk(Σk)) ≤O(γ(√m +\n√\nd)).\nWe wish to invoke Lemma 2.3. Let UDV T be the SVD of Y j, and let ˆU ˆD ˆV T be the SVD of\nXj. Now, for a matrix M, let ΠM denote the projection matrix of the subspace spanned by the\ncolumns of M. Deﬁne quantities a,b,z12,z21 as follows.\na = smin(UT XjV )\n= smin(UT Y jV + UT HV )\n= smin(UT Y jV )\n(Columns of U are orthogonal to columns of H)\n= sk(Y j)\n∈Θ(\n√\nm +\n√\nk)\n∈Θ(\n√\nm)\nb = ∥UT\n⊥XjV⊥∥\n= ∥UT\n⊥Y jV⊥+ UT\n⊥HV⊥∥\n= ∥UT\n⊥HV⊥∥\n(Columns of U⊥are orthogonal to columns of Y j)\n≤∥H∥\n≤O(γ(\n√\nm +\n√\nd))\nz12 = ∥ΠUHΠV⊥∥\n= 0\nz21 = ∥ΠU⊥HΠV ∥\n= ∥ΠU⊥Σ1/2\nd−k(Σ−1/2\nd−k H)ΠV ∥\n18\nNow, in the above, Σ−1/2\nd−k H ∈Rd×m, such that each of its entry is an independent sample\nfrom N (0,1). Right-multiplying it by ΠV makes it a matrix in a k-dimensional subspace\nof Rm, such that each row is an independent vector from a spherical Gaussian. Using Corol-\nlary 2.7, ∥Σ−1/2\nd−k H∥≤O(\n√\nd +\n√\nk) ≤O(\n√\nd) with probability at least 1 −0.01\nt . Also, ∥ΠU⊥Σ1/2\nd−k∥≤\nO(γ\np\nsk(Σk)) ≤O(γ). This gives us:\nz21 ≤O(γ\n√\nd).\nSince a2 > 2b2, we get the following by Lemma 2.3.\n∥Sin(Θ)(U, ˆU)∥≤\naz21 + bz12\na2 −b2 −min{z2\n12,z2\n21}\n≤O\n\n\nγ\n√\nd\n√m\n\n\nTherefore, using Lemma 2.4, and applying the union bound over all j, we get the required\nresult.\nLet ξ = O\n\u0012\nγ\n√\nd\n√m\n\u0013\n. We show that the projections of any reference point are close.\nCorollary 4.6. Let p1,...,pq be the reference points as deﬁned in Algorithm 2, and let Π and Πj (for\n1 ≤j ≤t) be projections matrices as deﬁned in Lemma 4.5. Then\nP\nh\n∀i,j,∥(Π −Πj)pi∥≤O(ξ(\n√\nk +\np\nln(qt)))\ni\n≥0.9.\nProof. We know from Lemma 4.5 that ∥Π −Πj∥≤ξ for all j with probability at least 0.95. For\nj ∈[t], let bΠj be the projection matrix for the union of the jth subspace and the subspace spanned\nby Σk. Lemma 2.10 implies that with probability at least 0.95, for all i,j, ∥bΠjpi∥≤O(\n√\nk+\np\nln(qt)).\nTherefore,\n∥(Π −Πj)pi∥= ∥(Π −Πj)bΠjpi∥≤∥Π −Πj∥· ∥bΠjpi∥≤O(ξ(\n√\nk +\np\nln(qt))).\nHence, the claim.\nThe above corollary shows that the projections of each reference point lie in a ball of radius\nO(ξ\n√\nk). Next, we show that for each reference point, all the projections of the point lie inside\na histogram cell with high probability. For notational convenience, since each point in Q is a\nconcatenation of the projection of all reference points on a given subspace, for all i,j, we refer\nto (0,...,0,Qj\n(i−1)d+1,...,Qj\nid,0,...,0) ∈Rqd (where there are (i −1)d zeroes behind Qj\n(i−1)d+1, and\n(q −i)d zeroes after Qj\nid) as pj\ni.\nLemma 4.7. Let ℓand λ be the length of a histogram cell and the random offset respectively, as deﬁned\nin Algorithm 2. Then\nP[|ω ∩Q| = t] ≥0.8.\nThus there exists ω ∈Ωthat, such that all points in Q lie within ω.\n19\nProof. Let r = O(ξ(\n√\nk +\np\nln(qt))). This implies that ℓ= 20r√q. The random offset could also be\nviewed as moving along a diagonal of a cell by λℓ\np\ndq. We know that with probability at least\n0.8, for each i, all projections of reference point pi lie in a ball of radius r. This means that all the\npoints in Q lie in a ball of radius r√q. Then\nP[|ω ∩Q| = t] ≤P\n\u0014 1\n20 ≥λ ∨λ ≥19\n20\n\u0015\n= 1\n10.\nTaking the union bound over all q and the failure of the event in Corollary 4.6, we get the\nclaim.\nNow, we analyse the sample complexity due to the private algorithm, that is, DP-histograms.\nLemma 4.8. Let ω be the histogram cell as deﬁned in Algorithm 2. Suppose Count(ω) is the noisy\ncount of ω as a result of applying the private histogram. If t ≥O\n\u0010log(1/δ)\nε\n\u0011\n, then\nP\n\u0014\n|Count(ω)| ≥t\n2\n\u0015\n≥0.75.\nProof. Lemma 4.7 implies that with probability at least 0.8, for each i, all projections of pi lie in a\nhistogram cell, that is, all points of Q lie in a histogram cell in Ω. Because of the error bound in\nLemma 2.15 and our bound on t, we see at least t\n2 points in that cell with probability at least\n1 −0.05. Therefore, by taking the union bound, the proof is complete.\nWe ﬁnally show that the error of the projection matrix that is output by Algorithm 2 is small.\nLemma 4.9. Let bΠ be the projection matrix as deﬁned in Algorithm 2, and n be the total number of\nsamples. If\nγ2 ∈O\n \nεα2n\nd2k ln(1/δ) · min\n(1\nk ,\n1\nln(k ln(1/δ)/ε)\n)!\n,\nn ≥O(k log(1/δ)\nε\n+ ln(1/δ)ln(ln(1/δ)/ε)\nε\n), and q ≥O(k) the with probability at least 0.7, ∥bΠ −Π∥≤α.\nProof. For each i ∈[q], let p∗\ni be the projection of pi on to the subspace spanned by Σk, bpi be as\ndeﬁned in the algorithm, and pj\ni be the projection of pi on to the subspace spanned by the jth\nsubset of X. From Lemma 4.8, we know that all pj\ni ’s are contained in a histogram cell of length ℓ.\nThis implies that p∗\ni is also contained within the same histogram cell.\nNow, let P = (p∗\n1,...,p∗\nq) and bP = (bp1,...,bpq). Then by above, bP = P + E, where ∥E∥F ≤2ℓ\np\ndq.\nTherefore, ∥E∥≤2ℓ\np\ndq. Let E = EP + EP , where EP is the component of E in the subspace\nspanned by P , and EP be the orthogonal component. Let P ′ = P + EP . We will be analysing bP\nwith respect to P ′.\nNow, with probability at least 0.95, sk(P ) ∈Θ(\n√\nk) due to our choice of q and using Corol-\nlary 2.7, and sk+1(P ) = 0. So, sk+1(P ′) = 0 because EP is in the same subspace as P . Now, using\nLemma 2.2, we know that sk(P ′) ≥sk(P ) −∥EP ∥≥Ω(\n√\nk) > 0. This means that P ′ has rank k, so\nthe subspaces spanned by Σk and P ′ are the same.\nAs before, we will try to bound the distance between the subspaces spanned by P ′ and bP .\nNote that using Lemma 2.1, we know that sk(P ′) ≤sk(P ) + ∥EP ∥≤O(\n√\nk).\n20\nWe wish to invoke Lemma 2.3 again. Let UDV T be the SVD of P ′, and let ˆU ˆD ˆV T be the SVD\nof bP . Now, for a matrix M, let ΠM denote the projection matrix of the subspace spanned by the\ncolumns of M. Deﬁne quantities a,b,z12,z21 as follows.\na = smin(UT bP V )\n= smin(UT P ′V + UT EP V )\n= smin(UT P ′V )\n(Columns of U are orthogonal to columns of EP )\n= sk(P ′)\n∈Θ(\n√\nk)\nb = ∥UT\n⊥bP V⊥∥\n= ∥UT\n⊥P ′V⊥+ UT\n⊥EP V⊥∥\n= ∥UT\n⊥EP V⊥∥\n(Columns of U⊥are orthogonal to columns of P ′)\n≤∥EP ∥\n≤O(ℓ\np\ndq)\nz12 = ∥ΠUEP ΠV⊥∥\n= 0\nz21 = ∥ΠU⊥EP ΠV ∥\n≤∥EP ∥\n≤O(ℓ\np\ndq)\nUsing Lemma 2.3, we get the following.\n∥Sin(Θ)(U, ˆU)∥≤\naz21 + bz12\na2 −b2 −min{z2\n12,z2\n21}\n≤O\n\u0010\nℓ\n√\ndk\n\u0011\n≤α\nThis completes our proof.\n4.3\nBoosting\nIn this subsection, we discuss boosting of error guarantees of Algorithm 2. The approach we\nuse is very similar to the well-known Median-of-Means method: we run the algorithm multiple\ntimes, and choose an output that is close to all other “good” outputs. We formalise this in\nAlgorithm 3.\nNow, we present the main result of this subsection.\nTheorem 4.10. Let Σ ∈Rd×d be an arbitrary, symmetric, PSD matrix of rank ≥k ∈{1,...,d}, and let\n0 < γ < 1. Suppose Π is the projection matrix corresponding to the subspace spanned by the vectors of\nΣk. Then given\nγ2 ∈O\n \nεα2n\nd2k ln(1/δ) · min\n(1\nk ,\n1\nln(k ln(1/δ)/ε)\n)!\n,\n21\nAlgorithm 3: DP Approximate Subspace Estimator Boosted DPASEBε,δ,α,β,γ,k(X)\nInput: Samples X1,...,Xn ∈Rd. Parameters ε,δ,α,β,γ,k > 0.\nOutput: Projection matrix bΠ ∈Rd×d of rank k.\nSet parameters: t ←C3 log(1/β)\nm ←⌊n/t⌋\nSplit X into t datasets of size m: X1,...,Xt.\n// Run DPASE t times to get multiple projection matrices.\nFor i ←1,...,t\nbΠi ←DPASEε,δ,α,γ,k(Xi)\n// Select a good subspace.\nFor i ←1,...,t\nci ←0\nFor j ∈[t] \\ {i}\nIf ∥bΠi −bΠj∥≤2α\nci ←ci + 1\nIf ci ≥0.6t −1\nReturn bΠi.\n// If there were not enough good subspaces, return ⊥.\nReturn ⊥.\nsuch that λk+1(Σ) ≤γ2λk(Σ), for every ε,δ > 0, and 0 < α,β < 1, there exists and (ε,δ)-DP algorithm\nthat takes\nn ≥O\n k log(1/δ)log(1/β)\nε\n+ log(1/δ)log(log(1/δ)/ε)log(1/β)\nε\n!\nsamples from N (⃗0,Σ), and outputs a projection matrix bΠ, such that ∥Π −bΠ∥≤α with probability at\nleast 1 −β.\nProof. Privacy holds trivially by Theorem 4.3.\nWe know by Theorem 4.3 that for each i, with probability at least 0.7, ∥bΠi −Π∥≤α. This\nmeans that by Lemma 2.9, with probability at least 1 −β, at least 0.6t of all the computed\nprojection matrices are accurate.\nThis means that there has to be at least one projection matrix that is close to 0.6t −1 > 0.5t of\nthese accurate projection matrices. So, the algorithm cannot return ⊥.\nNow, we want to argue that the returned projection matrix is accurate, too. Any projection\nmatrix that is close to at least 0.6t −1 projection matrices must be close to at least one accurate\nprojection matrix (by pigeonhole principle). Therefore, by triangle inequality, it will be close to\nthe true subspace. Therefore, the returned projection matrix is also accurate.\n22\nReferences\n[ABU18]\nR. Arora, V. Braverman, and J. Upadhyay. “Differentially private robust low-\nrank approximation”. In: Advances in neural information processing systems\n(2018).\n[ACGMMTZ16]\nM. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar,\nand L. Zhang. “Deep learning with differential privacy”. In: Proceedings of the\n2016 ACM SIGSAC conference on computer and communications security. 2016,\npp. 308–318.\n[ADKMV18]\nK. Amin, T. Dick, A. Kulesza, A. M. Medina, and S. Vassilvitskii. “Private\ncovariance estimation via iterative eigenvector sampling”. In: 2018 NIPS\nworkshop in Privacy-Preserving Machine Learning. Vol. 250. 2018.\n[BBDS12]\nJ. Blocki, A. Blum, A. Datta, and O. Sheffet. “The Johnson-Lindenstrauss Trans-\nform Itself Preserves Differential Privacy”. In: Proceedings of the 53rd Annual\nIEEE Symposium on Foundations of Computer Science. FOCS ’12. Washington,\nDC, USA: IEEE Computer Society, 2012, pp. 410–419.\n[BBNS19]\nJ. Błasiok, M. Bun, A. Nikolov, and T. Steinke. “Towards instance-optimal\nprivate query release”. In: Proceedings of the Thirtieth Annual ACM-SIAM\nSymposium on Discrete Algorithms. SIAM. 2019, pp. 2480–2497.\n[BCMNUW20]\nR. Bassily, A. Cheu, S. Moran, A. Nikolov, J. Ullman, and S. Wu. “Private\nquery release assisted by public data”. In: International Conference on Machine\nLearning. PMLR. 2020, pp. 695–703.\n[BDMN05]\nA. Blum, C. Dwork, F. McSherry, and K. Nissim. “Practical Privacy: The\nSuLQ Framework”. In: Proceedings of the 24th ACM SIGMOD-SIGACT-SIGART\nSymposium on Principles of Database Systems. PODS ’05. New York, NY, USA:\nACM, 2005, pp. 128–138.\n[BDRS18]\nM. Bun, C. Dwork, G. N. Rothblum, and T. Steinke. “Composable and Versatile\nPrivacy via Truncated CDP”. In: Proceedings of the 50th Annual ACM Symposium\non the Theory of Computing. STOC ’18. New York, NY, USA: ACM, 2018, pp. 74–\n86.\n[BLR08]\nA. Blum, K. Ligett, and A. Roth. “A Learning Theory Approach to Non-\nInteractive Database Privacy”. In: STOC. 2008.\n[BNS16]\nM. Bun, K. Nissim, and U. Stemmer. “Simultaneous Private Learning of Multi-\nple Concepts”. In: Proceedings of the 7th Conference on Innovations in Theoretical\nComputer Science. ITCS ’16. New York, NY, USA: ACM, 2016, pp. 369–380.\n[BS16]\nM. Bun and T. Steinke. “Concentrated Differential Privacy: Simpliﬁcations,\nExtensions, and Lower Bounds”. In: Proceedings of the 14th Conference on Theory\nof Cryptography. TCC ’16-B. Berlin, Heidelberg: Springer, 2016, pp. 635–658.\n23\n[BUV14]\nM. Bun, J. Ullman, and S. Vadhan. “Fingerprinting Codes and the Price of\nApproximate Differential Privacy”. In: Proceedings of the 46th Annual ACM\nSymposium on the Theory of Computing. STOC ’14. New York, NY, USA: ACM,\n2014, pp. 1–10.\n[CSS12]\nK. Chaudhuri, A. Sarwate, and K. Sinha. “Near-optimal differentially private\nprincipal components”. In: Advances in Neural Information Processing Systems\n25 (2012), pp. 989–997.\n[CZ16]\nT. Cai and A. Zhang. “Rate-Optimal Perturbation Bounds for Singular Sub-\nspaces with Applications to High-Dimensional Statistics”. In: The Annals of\nStatistics 46 (May 2016).\n[DMNS06]\nC. Dwork, F. McSherry, K. Nissim, and A. Smith. “Calibrating Noise to Sensi-\ntivity in Private Data Analysis”. In: Proceedings of the 3rd Conference on Theory\nof Cryptography. TCC ’06. Berlin, Heidelberg: Springer, 2006, pp. 265–284.\n[DSSUV15]\nC. Dwork, A. Smith, T. Steinke, J. Ullman, and S. Vadhan. “Robust Traceability\nfrom Trace Amounts”. In: Proceedings of the 56th Annual IEEE Symposium\non Foundations of Computer Science. FOCS ’15. Washington, DC, USA: IEEE\nComputer Society, 2015, pp. 650–669.\n[DTTZ14]\nC. Dwork, K. Talwar, A. Thakurta, and L. Zhang. “Analyze Gauss: Optimal\nBounds for Privacy-Preserving Principal Component Analysis”. In: Proceed-\nings of the 46th Annual ACM Symposium on the Theory of Computing. STOC ’14.\nNew York, NY, USA: ACM, 2014, pp. 11–20.\n[FT20]\nY. Feng and Y. Tu. “How neural networks ﬁnd generalizable solutions: Self-\ntuned annealing in deep learning”. In: arXiv preprint arXiv:2001.01678 (2020).\n[GARD18]\nG. Gur-Ari, D. A. Roberts, and E. Dyer. “Gradient descent happens in a tiny\nsubspace”. In: arXiv preprint arXiv:1812.04754 (2018).\n[GDGK20]\nQ. Geng, W. Ding, R. Guo, and S. Kumar. “Tight Analysis of Privacy and\nUtility Tradeoff in Approximate Differential Privacy”. In: Proceedings of the\nTwenty Third International Conference on Artiﬁcial Intelligence and Statistics. Ed.\nby S. Chiappa and R. Calandra. Vol. 108. Proceedings of Machine Learning\nResearch. PMLR, 2020, pp. 89–99.\n[GGB18]\nA. Gonem and R. Gilad-Bachrach. “Smooth Sensitivity Based Approach for\nDifferentially Private PCA”. In: Algorithmic Learning Theory. ALT ’18. JMLR,\nInc., 2018, pp. 438–450.\n[HP13]\nM. Hardt and E. Price. “The noisy power method: A meta algorithm with\napplications”. In: arXiv preprint arXiv:1311.2495 (2013).\n[HR10]\nM. Hardt and G. N. Rothblum. “A multiplicative weights mechanism for\nprivacy-preserving data analysis”. In: 2010 IEEE 51st Annual Symposium on\nFoundations of Computer Science. IEEE. 2010, pp. 61–70.\n24\n[HR12]\nM. Hardt and A. Roth. “Beating randomized response on incoherent matrices”.\nIn: Proceedings of the forty-fourth annual ACM symposium on Theory of computing.\n2012, pp. 1255–1268.\n[HR13]\nM. Hardt and A. Roth. “Beyond worst-case analysis in private singular vector\ncomputation”. In: Proceedings of the forty-ﬁfth annual ACM symposium on Theory\nof computing. 2013, pp. 331–340.\n[HT10]\nM. Hardt and K. Talwar. “On the Geometry of Differential Privacy”. In:\nProceedings of the 42nd Annual ACM Symposium on the Theory of Computing.\nSTOC ’10. New York, NY, USA: ACM, 2010, pp. 705–714.\n[KRRT20]\nP. Kairouz, M. Ribero, K. Rush, and A. Thakurta. Fast Dimension Independent\nPrivate AdaGrad on Publicly Estimated Subspaces. 2020.\n[KT13]\nM. Kapralov and K. Talwar. “On Differentially Private Low Rank Approxi-\nmation”. In: Proceedings of the 24th Annual ACM-SIAM Symposium on Discrete\nAlgorithms. SODA ’13. Philadelphia, PA, USA: SIAM, 2013, pp. 1395–1414.\n[LFLY18]\nC. Li, H. Farkhoor, R. Liu, and J. Yosinski. “Measuring the intrinsic dimension\nof objective landscapes”. In: arXiv preprint arXiv:1804.08838 (2018).\n[LGZCB20]\nX. Li, Q. Gu, Y. Zhou, T. Chen, and A. Banerjee. “Hessian based analysis of\nsgd for deep nets: Dynamics and generalization”. In: Proceedings of the 2020\nSIAM International Conference on Data Mining. SIAM. 2020, pp. 190–198.\n[LXTSG17]\nH. Li, Z. Xu, G. Taylor, C. Studer, and T. Goldstein. “Visualizing the loss\nlandscape of neural nets”. In: arXiv preprint arXiv:1712.09913 (2017).\n[MM09]\nF. McSherry and I. Mironov. “Differentially private recommender systems:\nBuilding privacy into the netﬂix prize contenders”. In: Proceedings of the 15th\nACM SIGKDD international conference on Knowledge discovery and data mining.\n2009, pp. 627–636.\n[MT07]\nF. McSherry and K. Talwar. “Mechanism Design via Differential Privacy”. In:\nProceedings of the 48th Annual IEEE Symposium on Foundations of Computer Sci-\nence. FOCS ’07. Washington, DC, USA: IEEE Computer Society, 2007, pp. 94–\n103.\n[NRS07]\nK. Nissim, S. Raskhodnikova, and A. Smith. “Smooth Sensitivity and Sam-\npling in Private Data Analysis”. In: Proceedings of the 39th Annual ACM Sympo-\nsium on the Theory of Computing. STOC ’07. New York, NY, USA: ACM, 2007,\npp. 75–84.\n[NS06]\nA. Narayanan and V. Shmatikov. “How to break anonymity of the netﬂix\nprize dataset”. In: arXiv preprint cs/0610105 (2006).\n[She19]\nO. Sheffet. “Old techniques in differentially private linear regression”. In:\nAlgorithmic Learning Theory. PMLR. 2019, pp. 789–827.\n[SU17]\nT. Steinke and J. Ullman. “Between Pure and Approximate Differential Pri-\nvacy”. In: The Journal of Privacy and Conﬁdentiality 7.2 (2017), pp. 3–22.\n25\n[Ull15]\nJ. Ullman. “Private multiplicative weights beyond linear queries”. In: Pro-\nceedings of the 34th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of\nDatabase Systems. 2015, pp. 303–312.\n[Vad17]\nS. Vadhan. “The Complexity of Differential Privacy”. In: Tutorials on the Foun-\ndations of Cryptography: Dedicated to Oded Goldreich. Ed. by Y. Lindell. Cham,\nSwitzerland: Springer International Publishing AG, 2017. Chap. 7, pp. 347–\n450.\n[Ver18]\nR. Vershynin. High-Dimensional Probability: An Introduction with Applications in\nData Science. Cambridge Series in Statistical and Probabilistic Mathematics.\nCambridge University Press, 2018.\n[WSCHT16]\nL. Wei, A. D. Sarwate, J. Corander, A. Hero, and V. Tarokh. “Analysis of a\nprivacy-preserving PCA algorithm using random matrix theory”. In: 2016\nIEEE Global Conference on Signal and Information Processing (GlobalSIP). IEEE.\n2016, pp. 1335–1339.\n[ZWB20]\nY. Zhou, Z. S. Wu, and A. Banerjee. “Bypassing the ambient dimension: Private\nsgd with gradient subspace identiﬁcation”. In: arXiv preprint arXiv:2007.03813\n(2020).\n26"
    }
]