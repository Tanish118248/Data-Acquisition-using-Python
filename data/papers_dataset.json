[
    {
        "title": "2106.00001",
        "year": "2021",
        "file_name": "2106.00001.pdf",
        "full_text": "Privately Learning Subspaces Vikrant Singhal * Thomas Steinke  Abstract Private data analysis suffers a costly curse of dimensionality. However, the data often has an underlying low-dimensional structure. For example, when optimizing via gradient de- scent, the gradients often lie in or near a low-dimensional subspace. If that low-dimensional structure can be identi ed, then we can avoid paying (in terms of privacy or accuracy) for the high ambient dimension. We present differentially private algorithms that take input data sampled from a low- dimensional linear subspace (possibly with a small amount of error) and output that subspace (or an approximation to it). These algorithms can serve as a pre-processing step for other procedures. 1 Introduction Differentially private algorithms generally have a poor dependence on the dimensionality of their input. That is, their error or sample complexity grows polynomially with the dimension. For example, for the simple task of estimating the mean of a distribution supported on [0,1]d, we have per-coordinate error  (   d/n) to attain differential privacy, where n is the number of samples. In contrast, the non-private error is  ( p log(d)/n). This cost of dimensionality is inherent [BUV14; SU17; DSSUV15]. Any method with lower error is susceptible to tracing attacks (a.k.a. membership inference attacks). However, these lower bounds only apply when the data distribution is  high-entropy.  This leaves open the posssibility that we can circumvent the curse of dimensionality when the data has an underlying low-dimensional structure. Data often does possess an underlying low-dimensional structure. For example, the gradients that arise in deep learning tend to be close to a low-dimensional subspace [ACGMMTZ16; LXTSG17; GARD18; LFLY18; LGZCB20; ZWB20; FT20]. Low dimensionality can arise from meaningful relationships that are at least locally linear, such as income versus tax paid. It can also arise because we are looking at a function of data with relatively few attributes. A long line of work [BLR08; HT10; HR10; Ull15; BBNS19; BCMNUW20; ZWB20; KRRT20, etc.] has shown how to exploit structure in the data to attain better privacy and accuracy. *Northeastern University. Part of this work was done during an internship at IBM Research   Al- maden. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . singhal.vi@northeastern.edu  Google Research, Brain Team. Part of this work was done at IBM Research   Al- maden. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . subspace@thomas-steinke.net 1 arXiv:2106.00001v3 [cs.CR] 10 Aug 2021 However, these approaches assume that this structure is known a priori or that it can be learned from non-private sources. This raises the question: Can we learn low-dimensional structure from the data subject to differential privacy? We consider the simple setting where the data lies in Rd but is in, or very close to a linear sub- space, of dimension k. We focus on the setting where k  d and we develop algorithms whose sample complexity does not depend on the ambient dimension d; a polynomial dependence on the true dimension k is unavoidable. Our algorithms identify the subspace in question or, if the data is perturbed slightly, an approximation to it. Identifying the subspace structure is interesting in its own right, but it also can be used as a pre-processing step for further analysis   by projecting to the low-dimensional subspace, we ensure subsequent data analysis steps do not need to deal with high-dimensional data. 1.1 Our Contributions: Privately Learning Subspaces   Exact Case We  rst consider the exact case, where the data X1,  ,Xn  Rd are assumed to lie in a k-dimensional subspace (rather than merely being near to it)   i.e., rank(A) = k, where A = Pn i XiXT i  Rd d. In this case, we can also recover the subspace exactly. However, we must also make some non-degeneracy assumptions. We want to avoid a pathological input dataset such as the following. Suppose X1,  ,Xk are linearly independent, but Xk = Xk+1 = Xk+2 =   = Xn. While we can easily reveal the repeated data point, we cannot reveal anything about the other points due to the privacy constraint. A natural non-degeneracy assumption would be to assume that the data points are in  general position    that is, that there are no non-trivial linear dependencies among the data points. This means that every set of k data points spans the subspace or, equivalently, no subspace of dimension k  1 contains more than k  1 data points. This is a very natural assumption   if the data consists of n samples from a continuous distribution on the subspace, then this holds with probability 1. We relax this assumption slightly and assume that no subspace of dimension k  1 contains more than  data points. We also assume that all points are non-zero. Note that we de ne subspaces to pass through the origin; our results can easily be extended to af ne subspaces. Theorem 1.1 (Main Result   Exact Case). For all n,d,k, N and  ,  > 0 satisfying n  O \u0010  + log(1/ )   \u0011 , there exists a randomized algorithm M : Rd n  Sk d satisfying the following. Here Sk d denotes the set of all k-dimensional subspaces of Rd.   M is ( , )-differentially private with respect to changing one column of its input.   Let X = (X1,  ,Xn)  Rd n. Suppose there exists a k-dimensional subspace S Sk d that contains all but  of the points   i.e., |{i  [n] : Xi  S }|  n . Further suppose that any (k 1)-dimensional subspace contains at most  points   i.e., for all S  Sk 1 d , we have |{i  [n] : Xi  S}|  . Then P[M(X) = S ] = 1. 2 The parameter  in Theorem 1.1 can be thought of as a robustness parameter. Ideally the data points are in general position, in which case  = k  1. If a few points are corrupted, then we increase  accordingly; our algorithm can tolerate the corruption of a small constant fraction of the data points. Theorem 1.1 is optimal in the sense that n   \u0010  + log(1/ )   \u0011 samples are required. 1.2 Our Contributions: Privately Learning Subspaces   Approximate Case Next we turn to the substantially more challenging approximate case, where the data X1,  ,Xn  Rd are assumed to be close to a k-dimensional subspace, but are not assumed to be contained within that subspace. Our algorithm for the exact case is robust to changing a few points, but very brittle if we change all the points by a little bit. Tiny perturbations of the data points (due to numerical errors or measurement imprecision) could push the point outside the subspace, which would cause the algorithm to fail. Thus it is important to for us to cover the approximate case and our algorithm for the approximate is entirely different from our algorithm for the exact case. The approximate case requires us to precisely quantify how close the input data and our output are to the subspace and we also need to make quantitative non-degeneracy assumptions. It is easiest to formulate this via a distributional assumption. We will assume that the data comes from a Gaussian distribution where the covariance matrix has a certain eigenvalue gap. This is a strong assumption and we emphasize that this is only for ease of presentation; our algorithm works under weaker assumptions. Furthermore, we stress that the differential privacy guarantee is worst-case and does not depend on any distributional assumptions. We assume that the data is drawn from a multivariate Gaussian N (0, ). Let  1( )    2( )    d( ) be the eigenvalues of    Rd d. We assume that there are k large eigen- values  1( ),  , k( )   these represent the  signal  we want   and d  k small eigenvalues  k+1( ),  , d( )   these are the  noise . Our goal is to recover the subspace spanned by the eigenvectors corresponding to the k largest eigenvalues  1( ),  , k( ). Our assumption is that there is a large multiplicative gap between the large and small eigenvalues. Namely, we assume  k+1( )  k( )   1 poly(d). Theorem 1.2 (Main Result   Approximate Case). For all n,d,k  N and  , , ,  > 0 satisfying n  k log(1/ )   + ln(1/ )ln(ln(1/ )/ )   ! and  2    2n d2k log(1/ )  min (1 k , 1 log(k log(1/ )/ ) )! , there exists an algorithm M : Rd n  Sk d satisfying the following. Here Sk d is the set of all k-dimensional subspaces of Rd represented as projection matricies   i.e., Sk d = {   Rd d :  2 =   =  T ,rank( ) = k}.   M is ( , )-differentially private with respect to changing one column of its input.   Let X1,  ,Xn be independent samples from N (0, ). Let  1( )  2( )    d( ) be the eigenvalues of    Rd d. Suppose  k+1( )  2    k( ). Let    Sk d be the projection matrix onto the subspace spanned by the eigenvectors corresponding to the k largest eigenvalues of  . Then P[ M(X)  ]  0.7. 3 The sample complexity of our algorithm n = O(k log(1/ )/ ) is independent of the ambient dimension d; this is ideal. However, there is a polynomial dependence on d in  , which controls the multiplicative eigenvalue gap. This multiplicative eigenvalue gap is a strong assumption, but it is also a necessary assumption if we want the sample complexity n to be independent of the dimension d. In fact, it is necessary even without the differential privacy constraint [CZ16]. That is, if we did not assume an eigenvalue gap that depends polynomially on the ambient dimension d, then it would be impossible to estimate the subspace with sample complexity n that is independent of the ambient dimension d even in the non-private setting. Our algorithm is based on the subsample and aggregate framework [NRS07] and a differ- entially private histogram algorithm. These methods are generally quite robust and thus our algorithm is, too. For example, our algorithm can tolerate o(n/k) input points being corrupted arbitrarily. We also believe that our algorithm s utility guarantee is robust to relaxing the Gaussianity assumption. All that we require in the analysis is that the empirical covariance matrix of a few samples from the distribution is suf ciently close to its expectation   with high probability. 1.3 Related Work To the best of our knowledge, the problem of privately learning subspaces, as we formulate it, has not been studied before. However, a closely-related line of work is on Private Principal Component Analysis (PCA) and low-rank approximations. We brie y discuss this extensive line of work below, but  rst we note that, in our setting, all of these techniques have a sample complexity n that grows polynomially with the ambient dimension d. Thus, they do not evade privacy s curse of dimensionality. However, we make a stronger assumption than these prior works   namely, we assume a large multiplicative eigenvalue gap. (Many of the prior works consider an additive eigenvalue gap, which is a weaker assumption.) There has been a lot of interest in Private PCA, matrix completion, and low-rank approx- imation. One motivation for this is the infamous Net ix prize, which can be interpreted as a matrix completion problem. The competition was cancelled after researchers showed that the public training data revealed the private movie viewing histories of many of Net ix s customers [NS06]. Thus privacy is a real concern for matrix analysis tasks. Many variants of these problems have been considered: Some provide approximations to the data matrix X = (X1,  ,Xn)  Rd n; others approximate the covariance matrix A = Pn i XiXT i   Rd d (as we do). There are also different forms of approximation   we can either produce a subspace or an approximation to the entire matrix, and the approximation can be measured by different norms (we consider the operator norm between projection matrices). Importantly, we de ne differential privacy to allow one data point Xi to be changed arbitrarily, whereas most of the prior work assumes a bound on the norm of the change or even assumes that only one coordinate of one vector can be changed. In the discussion below we focus on the techniques that have been considered for these problems, rather than the speci c results and settings. Dwork, Talwar, Thakurta, and Zhang [DTTZ14] consider the simple algorithm which adds independent Gaussian noise to each of entries of the covariance matrix A, and then perform analysis on the noisy matrix. (In fact, this algorithm predates the development of differential 4 privacy [BDMN05] and was also analyzed under differential privacy by McSherry and Mironov [MM09] and Chaudhuri, Sarwate, and Sinha [CSS12].) This simple algorithm is versatile and several bounds are provided for the accuracy of the noisy PCA. The downside of this is that a polynomial dependence on the ambient dimension d is inherent   indeed, they prove a sample complexity lower bound of n =  (   d) for any algorithm that identi es a useful approximation to the top eigenvector of A. This lower bound does not contradict our results because the relevant inputs do not satisfy our near low-rank assumption. Hardt and Roth [HR12] and Arora, Braverman, and Upadhyay [ABU18] apply techniques from dimensionality reduction to privately compute a low-rank approximation to the input matrix X. Hardt and Roth [HR13] and Hardt and Price [HP13] use the power iteration method with noise injected at each step to compute low-rank approximations to the input matrix X. In all of these, the underlying privacy mechanism is still noise addition and the results still require the sample complexity to grow polynomially with the ambient dimension to obtain interesting guarantees. (However, the results can be dimension-independent if we de ne differential privacy so that only one entry   as opposed to one column   of the matrix X can be changed by 1. This is a signi cantly weaker privacy guarantee.) Blocki, Blum, Datta, and Sheffet [BBDS12] and Sheffet [She19] also use tools from dimen- sionality reduction; they approximate the covariance matrix A. However, they show that the dimensionality reduction step itself provides a privacy guarantee (whereas the aforementioned results did not exploit this and relied on noise added at a later stage). Sheffet [She19] analyzes two additional techniques   the addition of Wishart noise (i.e., Y Y T where the columns of Y are independent multivariate Gaussians) and sampling from an inverse Wishart distribution (which has a Bayesian interpretation). Chaudhuri, Sarwate, and Sinha [CSS12], Kapralov and Talwar [KT13], Wei, Sarwate, Coran- der, Hero, and Tarokh [WSCHT16], and Amin, Dick, Kulesza, Medina, and Vassilvitskii [AD- KMV18] apply variants of the exponential mechanism [MT07] to privately select a low-rank approximation to the covariance matrix A. This method is nontrivial to implement and analyse, but it ultimately requires the sample complexity to grow polynomially in the ambient dimension. Gonem and Gilad-Bachrach [GGB18] exploit smooth sensitivity [NRS07] to release a low- rank approximation to the matrix A. This allows adding less noise than worst case sensitivity, under an eigenvalue gap assumption. However, the sample complexity n is polynomial in the dimension d. Limitations of Prior Work Given the great variety of techniques and analyses that have been applied to differentially private matrix analysis problems, what is missing? We see that almost all of these techniques are ultimately based on some form of noise addition or the exponential mechanism. With the singular exception of the techniques of Sheffet [She19], all of these prior techniques satisfy pure1 or concentrated differential privacy [BS16]. This is enough to conclude that these techniques cannot yield the dimension-independent guarantees that we seek. No amount of postprocessing or careful analysis can avoid this limitation. This is because pure and concentrated differential privacy have strong group privacy properties, which means  packing  lower bounds [HT10] apply. 1Pure differential privacy (a.k.a. pointwise differential privacy) is ( , )-differential privacy with   = 0. 5 We brie y sketch why concentrated differential privacy is incompatible with dimension- independent guarantees. Let the input be X1 = X2 =   = Xn =  /   d for a uniformly random    { 1,+1}d. That is, the input is one random point repeated n times. If M satis es O(1)- concentrated differential privacy, then it satis es the mutual information bound I(M(X);X)   O(n2) [BS16]. But, if M provides a meaningful approximation to X or A = XXT , then we must be able to recover an approximation to   from its output, whence I(M(X);X)  (d), as the entropy of X is d bits. This gives a lower bound of n  (   d), even though X and A have rank k = 1. The above example shows that, even under the strongest assumptions (i.e., the data lies exactly in a rank-1 subspace), any good approximation to the subspace, to the data matrix X, or to the covariance matrix A = XXT must require the sample complexity n to grow polynomially in the ambient dimension d if we restrict to techniques that satisfy concentrated differential privacy. Almost all of the prior work in this general area is subject to this restriction. To avoid a sample complexity n that grows polynomially with the ambient dimension d, we need fundamentally new techniques. 1.4 Our Techniques For the exact case, we construct a score function for subspaces that has low sensitivity, assigns high score to the correct subspace, and assigns a low score to all other subspaces. Then we can simply apply a GAP-MAX algorithm to privately select the correct subspace [BDRS18]. The GAP-MAX algorithm satis es ( , )-differential privacy and outputs the correct subspace as long as the gap between its score and that of any other subspace is larger than O(log(1/ )/ ). This works even though there are in nitely many subspaces to consider, which would not be possible under concentrated differential privacy. The simplest score function would simply be the number of input points that the subspace contains. This assigns high score to the correct subspace, but it also assigns high score to any larger subspace that contains the correct subspace. To remedy this, we subtract from the score the number of points contained in a strictly smaller subspace. That is, the score of subspace S is the number of points in S minus the maximum over all subspaces S   S of the number of points contained in S . This GAP-MAX approach easily solves the exact case, but it does not readily extend to the approximate case. If we count points near to the subspace, rather than in it, then (in nitely) many subspaces will have high score, which violates the assumptions needed for GAP-MAX to work. Thus we use a completely different approach for the approximate case. We apply the  subsample and aggregate  paradigm of [NRS07]. That is, we split the dataset X1,  ,Xn into n/O(k) sub-datasets each of size O(k). We use each sub-dataset to compute an approximation to the subspace by doing a (non-private) PCA on the sub-dataset. Let   be the projection matrix onto the correct subspace and  1,  , n/O(k) the projection matrices onto the approximations derived from the sub-datasets. With high probability  j  is small for most j. (Exactly how small depends on the eigengap.) Now we must privately aggregate the projection matrices  1,  , n/O(k) into a single projection matrix. Rather than directly trying to aggregate the projection matrices, we pick a set of reference points, project them onto the subspaces, and then aggregate the projected points. We draw 6 p1,  ,pO(k) independently from a standard spherical Gaussian. Then  jpi  pi j   O(   k) is also small for all i and most j. We wish to privately approximate  pi and to do this we have n/O(k) points  jpi most of which are close to  pi. This is now a location or mean estimation problem, which we can solve privately. Thus we obtain points  pi such that  pi  pi  is small for all i. From a PCA of these points we can obtain a projection   with    being small, as required. Finally, we discuss how to privately obtain (  p1,  p2,  ,  pO(k)) from ( 1p1,  , 1pO(k)),  , ( n/O(k)p1,  , n/O(k)pO(k)). It is better here to treat (  p1,  p2,  ,  pO(k)) as a single vector in RO(kd), rather than as O(k) vectors in Rd. We split RO(kd) into cells and then run a differentially private histogram algorithm. If we construct the cells carefully, for most j we have that ( jp1,  , jpO(k)) is in the same histogram cell as the desired point ( p1,  , pO(k)). The histogram algorithm will thus identify this cell, and we take an arbitrary point from this cell as our estimate (  p1,  p2,  ,  pO(k)). The differentially private histogram algorithm is run over expo- nentially many cells, which is possible under ( , )-differential privacy if n/O(k)  O(log(1/ )/ ). (Note that under concentrated differential privacy the histogram algorithm s sample complexity n would need to depend on the number of cells and, hence, the ambient dimension d.) The main technical ingredients in the analysis of our algorithm for the approximate case are matrix perturbation and concentration analysis and the location estimation procedure using differentially private histograms. Our matrix perturbation analysis uses a variant of the Davis-Kahan theorem to show that if the empirical covariance matrix is close to the true covariance matrix, then the subspaces corresponding to the top k eigenvalues of each are also close; this is applied to both the subsamples and the projection of the reference points. The matrix concentration results that we use show that the empirical covariance matrices in all the subsamples are close to the true covariance matrix. This is the only place where the multivariate Gaussian assumption arises. Any distribution that concentrates well will work. 2 Notations, De nitions, and Background Results 2.1 Linear Algebra and Probability Preliminaries Here, we mention a few key technical results that we will be using to prove the main theorem for the approximate case. Throughout this document, we assume that the dimension d is larger than some absolute constant, and adopt the following notation: for a matrix A of rank r, we use s1(A)    sr(A) to denote the singular values of A in decreasing order, and use  1(A)    r(A) to denote the eigenvalues of A in decreasing order; let smin(A) denote the least, non-zero singular value of A. We omit the parentheses when the context is clear. We begin by stating two results about matrix perturbation theory. The  rst result says that if two matrices are close to one another in operator norm, then their corresponding singular values are also close to one another. De ne  M := sup{ Mx 2 : x  Rd,  x 2  1} to be the operator norm with respect to the Euclidean vector norm. 7 Lemma 2.1 (Singular Value Inequality). Let A,B  Rd n and let r = min{d,n}. Then for 1  i,j  r, si+j 1(A + B)  si(A) + sj(B). The following result gives a lower bound on the least singular value of sum of two matrices. Lemma 2.2 (Least Singular Value of Matrix Sum). Let A,B  Rd n. Then smin(A + B)  smin(A)  B . The next result bounds the angle between the subspaces spanned by two matrices that are close to one another. Let X  Rd n have the following SVD. X = h U U  i   \"  1 0 0  2 #   \" V T V T   # In the above, U,U are orthonormal matrices such that U  Rd r and U Rd (d r),  1, 2 are diagonal matrices, such that  1  Rr r and  2  R(d r) (n r), and V ,V are orthonormal matrices, such that V  Rn r and V Rn (n r). Let Z  Rd n be a perturbation matrix, and  X = X + Z, such that  X has the following SVD.  X = h  U  U  i   \"  1 0 0  2 #   \"  V T  V T   # In the above,  U,  U ,  1,  2,  V ,  V have the same structures as U,U , 1, 2,V ,V respectively. Let Z21 = U UT  ZV V T and Z12 = UUT ZV V T  . Suppose  1    r  0 are the singular values of UT  U. Let  (U,  U)  Rr r be a diagonal matrix, such that  ii(U,  U) = cos 1( i). Lemma 2.3 (Sin( ) Theorem [CZ16]). Let X,  X,Z,Z12,Z21 be de ned as above. Denote   = smin(UT  XV ) and   =  UT  XV . If  2 >  2 + min{ Z12 2, Z21 2}, then we have the following.  Sin( )(U,  U)   Z21 +  Z12   2  2  min{ Z12 2, Z21 2} The next result bounds  Sin( )(U,  U) in terms of the distance between UUT and  U  UT . Lemma 2.4 (Property of  Sin( ) [CZ16]). Let U,  U  Rd r be orthonormal matrices, and let  (U,  U) be de ned as above in terms of  U,U. Then we have the following.  Sin( )(U,  U) U  UT  UUT  2 Sin( )(U,  U)  The next result bounds the singular values of a matrix, whose columns are independent vectors from a mean zero, isotropic distribution in Rd. We  rst de ne the sub-Gaussian norm of a random variable. De nition 2.5. Let X be a sub-Gaussian random variable. The sub-Gaussian norm of X, denoted by  X 2, is de ned as,  X 2 = inf{t > 0 : E h exp(X2/t2) i  2}. 8 Lemma 2.6 (Theorem 4.6.1 [Ver18]). Let A be an n   m matrix, whose columns Ai are independent, mean zero, sub-Gaussian isotropic random vectors in Rn. Then for any t  0, we have   m  CK2(   n + t)  sn(A)  s1(A)     m + CK2(   n + t) with probability at least 1  2exp( t2). Here, K = maxi  A 2 (sub-Gaussian norm of A). In the above,  A 2  O(1) if the distribution in question is N ( 0,I). The following corollary generalises the above result for arbitrary Gaussians. Corollary 2.7. Let A be an n   m matrix, whose columns Ai are independent, random vectors in Rn from N ( 0, ). Then for any t  0, we have (   m  CK2(   n + t)) p sn( )  sn(A)  (   m + CK2(   n + t)) p sn( ) and s1(A)  (   m + CK2(   n + t)) p s1( ) with probability at least 1  2exp( t2). Here, K = maxi  A 2 (sub-Gaussian norm of A). Proof. First, we prove the lower bound on sn(A). Note that sn(A) = min  x >0  Ax   x , and that the columns of  1 2 A are distributed as N ( 0,I). Therefore, we have the following. min  x >0  Ax   x = min  x >0   1 2  1 2 Ax   x  = min  x >0   1 2  1 2 Ax   1 2 Ax   1 2 Ax   x   min  x >0   1 2  1 2 Ax   1 2 Ax  min  x >0  1 2 Ax   x   min  y >0   1 2 y   y  min  x >0  1 2 Ax   x   (   m  CK2(   n + t)) p sn( ) (Lemma 2.6) Next, we prove the upper bound on sn(A). For this, we  rst show that for X  Rm d and Y  Rd n, smin(XY )  smin(X)    Y  . smin(XY ) = min  z =1 XY z   min  z =1 X Y z  =  X  min  z =1 Y z  =  X  smin(Y ) Now, smin(XY ) = smin(Y T XT )  Y  smin(X) by the above reasoning. Using this results, we have the following. sn(A) = sn( 1/2    1/2A) 9  sn( 1/2) 1/2A   (   m + CK2(   n + t)) p sn( ) (Lemma 2.6) Now, we show the upper bound on s1(A). Note that s1(A) =  A .  A =   1 2  1 2 A    1 2    1 2 A   (   m + CK2(   n + t)) p s1( ) (Lemma 2.6) This completes the proof. Now, we state a concentration inequality for  2 random variables. Lemma 2.8. Let X be a  2 random variable with k degrees of freedom. Then, P h X > k + 2   kt + 2t i  e t. Next, we state the well-known Bernstein s inequality for sums of independent Bernoulli random variables. Lemma 2.9 (Bernstein s Inequality). Let X1,...,Xm be independent Bernoulli random variables taking values in {0,1}. Let p = E[Xi]. Then for m  5p 2 2 ln(2/ ) and    p/4, P \u0014 1 m X Xi  p   \u0015  2e 2m/2(p+ )  . We  nally state a result about the norm of a vector sampled from N ( 0,I). Lemma 2.10. Let X1,...,Xq  N ( 0, ) be vectors in Rd, where   is the projection of Id d on to a subspace of Rd of rank k. Then P h  i, Xi 2  k + 2   kt + 2t i  1  qe t. Proof. Since   is of rank k, we can directly use Lemma 2.8 for a  xed i  [q], and the union bound over all i  [q] to get the required result. This is because for any i,  Xi 2 is a  2 random variable with k degrees of freedom. 2.2 Privacy Preliminaries De nition 2.11 (Differential Privacy (DP) [DMNS06]). A randomized algorithm M : X n  Y satis es ( , )-differential privacy (( , )-DP) if for every pair of neighboring datasets X,X   X n (i.e., datasets that differ in exactly one entry),  Y  Y P[M(X)  Y ]  e    P\u0002M(X )  Y \u0003 +  . When   = 0, we say that M satis es  -differential privacy or pure differential privacy. 10 Neighbouring datasets are those that differ by the replacement of one individual s data. In our setting, each individual s data is assumed to correspond to one point in X = Rd, so neighbouring means one point is changed arbitrarily. Throughout the document, we will assume that   is smaller than some absolute constant less than 1 for notational convenience, but note that our results still hold for general  . Now, this privacy de nition is closed under post-processing. Lemma 2.12 (Post Processing [DMNS06]). If M : X n  Y is ( , )-DP, and P : Y  Z is any randomized function, then the algorithm P  M is ( , )-DP. 2.3 Basic Differentially Private Mechanisms. We  rst state standard results on achieving privacy via noise addition proportional to sensitivity [DMNS06]. De nition 2.13 (Sensitivity). Let f : X n  Rd be a function, its  1-sensitivity and  2-sensitivity are  f ,1 = max X X X n  f (X)  f (X ) 1 and  f ,2 = max X X X n  f (X)  f (X ) 2, respectively. Here, X  X  denotes that X and X  are neighboring datasets (i.e., those that differ in exactly one entry). One way of introducing ( , )-differential privacy is via adding noise sampled from the truncated Laplace distribution, proportional to the  1 sensitivity. Lemma 2.14 (Truncated Laplace Mechanism [GDGK20]). De ne the probability density function (p) of the truncated Laplace distribution as follows. p(x) =   Be |x|   if x  [ A,A] 0 otherwise In the above,   =     , A =     log 1 + e   1 2  ! , B = 1 2 (1  e A   ) . Let TLap( , , ) denote a draw from the above distribution. Let f : X n  Rd be a function with sensitivity  . Then the truncated Laplace mechanism M(X) = f (X) + TLap( , , ) satis es ( , )-DP. In the above A    f ,1   log(1/ ) since   is smaller than some absolute constant less than 1. Now, we introduce differentially private histograms. Lemma 2.15 (Private Histograms). Let n  N,  , ,  > 0, and X a set. There exists M : X n  RX which is ( , )-differentially private and, for all x  X n, we have P M    sup y X M(x)y  1 n|{i  [n] : xi = y}|  O log(1/ )  n !   1  . 11 The above holds due to [BNS16; Vad17]. Finally, we introduce the GAP-MAX algorithm from [BDRS18] that outputs the element from the output space that has the highest score function, given that there is a signi cant gap between the scores of the highest and the second to the highest elements. Lemma 2.16 (GAP-MAX Algorithm [BDRS18]). Let SCORE : X n   Y  R be a score function with sensitivity 1 in its  rst argument, and let  ,  > 0. Then there exists a ( , )-differentially private algorithm M : X n  Y and   =  (log(1/ )/ n) with the following property. Fix an input X  X n. Let y = argmax y Y {SCORE(X,y)}. Suppose  y  Y,y , y = SCORE(X,y) < SCORE(X,y )  n. Then M outputs y with probability 1. 3 Exact case Here, we discuss the case, where all n points lie exactly in a subspace s of dimension k of Rd. Our goal is to privately output that subspace. We do it under the assumption that all strict subspaces of s contain at most  points. If the points are in general position, then  = k 1, as any strictly smaller subspace has dimension < k and cannot contain more points than its dimension. Let Sk d be the set of all k-dimensional subspaces of Rd. Let Sd be the set of all subspaces of Rd. We formally de ne that problem as follows. Problem 3.1. Assume (i) all but at most  , input points are in some s Sk d, and (ii) every subspace of dimension < k contains at most  points. (If the points are in general position   aside from being contained in s  then  = k  1.) The goal is to output a representation of s . We call these  points that do not lie in s ,  adversarial points . With the problem de ned in Problem 3.1, we will state the main theorem of this section. Theorem 3.2. For any  ,  > 0,  k  1  0, and n  O  + log(1/ )   ! , there exists an ( , )-DP algorithm M : Rd n  Sk d, such that if X is a dataset of n points satisfying the conditions in Problem 3.1, then M(X) outputs a representation of s with probability 1. We prove Theorem 3.2 by proving the privacy and the accuracy guarantees of Algorithm 1. The algorithm performs a GAP-MAX (cf. Lemma 2.16). It assigns a score to all the relevant subspaces, that is, the subspaces spanned by the points of the dataset X. We show that the only subspace that has a high score is the true subspace s , and the rest of the subspaces have low scores. Then GAP-MAX outputs the true subspace successfully because of the gap between the scores of the best subspace and the second to the best one. For GAP-MAX to work all the time, 12 we de ne a default option in the output space that has a high score, which we call NULL. Thus, the output space is now Y = Sd  {NULL}. Also, for GAP-MAX to run in  nite time, we  lter Sd to select  nite number of subspaces that have at least 0 scores on the basis of X. Note that this is a preprocessing step, and does not violate privacy as, we will show, all other subspaces already have 0 probability of getting output. We de ne the score function u : X n   Y  N as follows. u(x,s) :=   |x  s|  sup{|x  t| : t  Sd,t  s} if s  Sd  + 4log(1/ )   + 1 if s = NULL Note that this score function can be computed in  nite time because for any m points and i > 0, if the points are contained in an i-dimensional subspace, then the subspace that contains all m points must lie within the set of subspaces spanned by \u0000 m i+1 \u0001 subsets of points. Algorithm 1: DP Exact Subspace Estimator DPESE , ,k, (X) Input: Samples X  Rd n. Parameters  , ,k, > 0. Output:  s  Sk d. Set Y  {NULL} and sample noise  (NULL) from TLap(2, , ). Set score u(X,NULL) =  + 4log(1/ )   + 1. // Identify candidate outputs. For each subset S of X of size k Let s be the subspace spanned by S. Y  Y  {s}. Sample noise  (s) from TLap(2, , ). Set score u(X,s) = |x  s|  sup{|x  t| : t  Sd,t  s}. // Apply GAP-MAX. Let s1 = argmaxs Y u(X,s) be the candidate with the largest score. Let s2 = argmaxs Y\\{s1} u(X,s) be the candidate with the second-largest score. Let  s = argmaxs Y max{0,u(X,s)  u(X,s2)  1} +  (s). // Truncated Laplace noise    TLap(2, , ); see Lemma 2.14 Return  s. We split the proof of Theorem 1.1 into sections for privacy (Lemma 3.3) and accuracy (Lemma 3.5). 3.1 Privacy Lemma 3.3. Algorithm 1 is ( , )-differentially private. The proof of Lemma 3.3 closely follows the privacy analysis of GAP-MAX by [BDRS18]. The only novelty is that Algorithm 1 may output NULL in the case that the input is malformed (i.e., doesn t satisfy the assumptions of Problem 3.1). The key is that the score u(X,s) is low sensitivity. Thus max{0,u(X,s)  u(X,s2)  1} also has low sensitivity. What we gain from subtracting the second-largest score and taking this 13 maximum is that these values are also sparse   only one (s = s1) is nonzero. This means we can add noise to all the values without paying for composition. We now prove Lemma 3.3. Proof. First, we argue that the sensitivity of u is 1. The quantity |X  s| has sensitivity 1 and so does sup{|X  t| : t  Sd,t  s}. This implies sensitivity 2 by the triangle inequality. However, we see that it is not possible to change one point that simultaneously increases |X  s| and decreases sup{|X  t| : t  Sd,t  s} or vice versa. Thus the sensitivity is actually 1. We also argue that u(X,s2) has sensitivity 1, where s2 is the candidate with the second-largest score. Observe that the second-largest score is a monotone function of the collection of all scores   i.e., increasing scores cannot decrease the second-largest score and vice versa. Changing one input point can at most increase all the scores by 1, which would only increase the second-largest score by 1. This implies that max{0,u(X,s)  u(X,s2)  1} has sensitivity 2 by the triangle inequality and the fact that the maximum does not increase the sensitivity. Now we observe that for any input X there is at most one s such that max{0,u(X,s) u(X,s2)  1} , 0, namely s = s1. We can say something even stronger: Let X and X  be neighbouring datasets with s1 and s2 the largest and second-largest scores on X and s  1 and s  2 the largest and second-largest scores on X . Then there is at most one s such that max{0,u(X,s) u(X,s2) 1} , 0 or max{0,u(X ,s)  u(X ,s  2)  1} , 0. In other words, we cannot have both u(X,s1)  u(X,s2) > 1 and u(X ,s  1)  u(X ,s  2) > 1 unless s1 = s  1. This holds because u(X,s)  u(X,s2) has sensitivity 2. With these observations in hand, we can delve into the privacy analysis. Let X and X  be neighbouring datasets with s1 and s2 the largest and second-largest scores on X and s  1 and s  2 the largest and second-largest scores on X . Let Y be the set of candidates from X and let Y  be the set of candidates from X . Let  Y = Y  Y  and  Y = Y  Y . We note that, for s  Y, if u(X,s)  , then there is no way that  s = s. This is because | (s)|  2log(1/ )   for all s and hence, there is no way we could have argmaxs Y max{0,u(X,s)   u(X,s2)  1} +  (s)  argmaxs Y max{0,u(X,NULL)  u(X,s2)  1} +  (NULL). If s  Y \\  Y, then u(X,s)  |X  s|  k + 1  and u(X ,s)  . This is because s <  Y implies |X  s| < k or |X   s| < k, but |X  s|  |X   s| + 1. Thus, there is no way these points are output and, hence, we can ignore these points in the privacy analysis. (This is the reason for adding the NULL candidate.) Now we argue that the entire collection of noisy values max{0,u(X,s)  u(X,s2)  1} +  (s) for s  Y is differentially private. This is because we are adding noise to a vector where (i) on the neighbouring datasets only 1 coordinate is potentially different and (ii) this coordinate has sensitivity 2. 3.2 Accuracy We start by showing that the true subspace s has a high score, while the rest of the subspaces have low scores. Lemma 3.4. Under the assumptions of Problem 3.1, u(x,s )  n  2 and u(x,s )  2 for s  , s . Proof. We have u(x,s ) = |x  s |  |x  s | for some s   Sd with s   s . The dimension of s  is at most k  1 and, by the assumption (ii), |x  s |  . 14 Let s   Sd \\ {s }. There are three cases to analyse: 1. Let s   s . Then u(x,s )  |x  s |  |x  s |  because the  adverserial points and the  n  non-adversarial points may not together lie in a subspace of dimension k. 2. Let s   s . Let k  be the dimension of s . Clearly k  < k. By our assumption (ii), |s   x|  . Then u(x,s ) = |x s | |x t|  for some t because the  adversarial points already don t lie in s , so they will not lie in any subspace of s . 3. Let s  be incomparable to s . Let s  = s   s . Then u(x,s )  |x  s |  |x  s |  because the adversarial points may not lie in s , but could be in s  \\ s . This completes the proof. Now, we show that the algorithm is accurate. Lemma 3.5. If n  3 + 8log(1/ )   + 2, then Algorithm 1 outputs s for Problem 3.1. Proof. From Lemma 3.4, we know that s has a score of at least n 2 , and the next best subspace can have a score of at most  . Also, the score of NULL is de ned to be  + 4log(1/ )   + 1. This means that the gap satis es max{0,u(X,s ) u(X,s2) 1}  n 3 4log(1/ )    1. Since the noise is bounded by 2log(1/ )   , our bound on n implies that  s = s  3.3 Lower Bound Here, we show that our upper bound is optimal up to constants for the exact case. Theorem 3.6. Any ( , )-DP algorithm that takes a dataset of n points satisfying the conditions in Problem 3.1 and outputs s with probability > 0.5 requires n   \u0010  + log(1/ )   \u0011 . Proof. First, n  +k. This is because we need at least k points to span the subspace, and  points could be corrupted. Second, n  (log(1/ )/ ) by group privacy. Otherwise, the algorithm is (10,0.1)-differentially private with respect to changing the entire dataset and it is clearly impossible to output the subspace under this condition. 4 Approximate Case In this section, we discuss the case, where the data  approximately  lies in a k-dimensional subspace of Rd. We make a Gaussian distributional assumption, where the covariance is approximately k-dimensional, though the results could be extended to distributions with heavier tails using the right inequalities. We formally de ne the problem: Problem 4.1. Let    Rd d be a symmetric, PSD matrix of rank  k  {1,...,d}, and let 0 <    1, such that  k+1  k  2. Suppose   is the projection matrix corresponding to the subspace spanned by the eigenvectors of   corresponding to the eigenvalues  1,..., k. Given sample access to N ( 0, ), and 0 <   < 1, output a projection matrix b , such that    b . 15 We solve Problem 4.1 under the constraint of ( , )-differential privacy. Throughout this section, we would refer to the subspace spanned by the top k eigenvectors of   as the  true  or  actual  subspace. Algorithm 2 solves Problem 4.1 and proves Theorem 1.2. Here    is the operator norm. Remark 4.2. We scale the eigenvalues of   so that  k = 1 and  k+1  2. Also, for the purpose of the analysis, we will be splitting   =  k +  d k, where  k is the covariance matrix formed by the top k eigenvalues and the corresponding eigenvectors of   and  d k is remainder. Also, we assume the knowledge of   (or an upper bound on  ). Our solution is presented in Algorithm 2. The following theorem is the main result of the section. Theorem 4.3. Let    Rd d be an arbitrary, symmetric, PSD matrix of rank  k  {1,...,d}, and let 0 <   < 1. Suppose   is the projection matrix corresponding to the subspace spanned by the vectors of  k. Then given  2  O  2n d2k ln(1/ )   min (1 k , 1 ln(k ln(1/ )/ ) )! , such that  k+1( )  2 k( ), for every  ,  > 0, and 0 <   < 1, there exists and ( , )-DP algorithm that takes n  O k log(1/ )   + log(1/ )log(log(1/ )/ )   ! samples from N ( 0, ), and outputs a projection matrix b , such that    b  with probability at least 0.7. Algorithm 2 is a type of  Subsample-and-Aggregate  algorithm [NRS07]. Here, we consider multiple subspaces formed by the points from the same Gaussian, and privately  nd a subspace that is close to all those subspaces. Since the subspaces formed by the points would be close to the true subspace, the privately found subspace would be close to the true subspace. A little more formally, we  rst sample q public data points (called  reference points ) from N ( 0,I). Next, we divide the original dataset X into disjoint datasets of m samples each, and project all reference points on the subspaces spanned by every subset. Now, for every reference point, we do the following. We have t = n m projections of the reference point. Using DP histogram over Rd, we aggregate those projections in the histogram cells; with high probability all those projections will be close to one another, so they would lie within one histogram cell. We output a random point from the histogram cell corresponding to the reference point. With a total of q points output in this way, we  nally output the projection matrix spanned by these points. In the algorithm C0, C1, and C2 are universal constants. We divide the proof of Theorem 4.3 into two parts: privacy (Lemma 4.4) and accuracy (Lemma 4.9). 4.1 Privacy We analyse the privacy by understanding the sensitivities at the only sequence of steps invok- ing a differentially private mechanism, that is, the sequence of steps involving DP-histograms. 16 Algorithm 2: DP Approximate Subspace Estimator DPASE , , , ,k(X) Input: Samples X1,...,Xn  Rd. Parameters  , , , ,k > 0. Output: Projection matrix b   Rd d of rank k. Set parameters: t  C0 ln(1/ )   m  n/t  q  C1k   C2    dk(   k+  ln(kt))  m Sample reference points p1,...,pq from N ( 0,I) independently. // Subsample from X, and form projection matrices. For j  1,...,t Let Xj = (X(j 1)m+1,...,Xjm)  Rd m. Let  j  Rd d be the projection matrix onto the subspace spanned by the eigenvectors of Xj(Xj)T  Rd d corresponding to the largest k eigenvalues. For i  1,...,q pj i  jpi // Create histogram cells with random offset. Let   be a random number in [0,1). Divide Rqd into  = {...,[ + i , + (i + 1) ),...}qd, for all i  Z. Let each disjoint cell of length  be a histogram bucket. // Perform private aggregation of subspaces. For each i  [q], let Qi  Rd t be the dataset, where column j is pj i. Let Q  Rqd t be the vertical concatenation of all Qi s in order. Run ( , )-DP histogram over  using Q to get    that contains at least t 2 points. If no such   exists Return   // Return the subspace. Let bp = (bp1,...,bpd,...,bp(q 1)d+1,...,bpqd) be a random point in  . For each i  [q] Let bpi = (bp(i 1)d+1,...,bpid). Let b  be the projection matrix of the top-k subspace of (bp1,...,bpq). Return b . Lemma 4.4. Algorithm 2 is ( , )-differentially private. Proof. Changing one point in X can change only one of the Xj s. This can only change one point in Q, which in turn can only change the counts in two histogram cells by 1. Therefore, the sensitivity is 2. Because the sensitivity of the histogram step is bounded by 2 (Lemma 4.4), an application of DP-histogram, by Lemma 2.15, is ( , )-DP. Outputting a random point in the privately found histogram cell preserves privacy by post-processing (Lemma 2.12). Hence, the claim. 17 4.2 Accuracy Now we delve into the utility analysis of the algorithm. For 1  j  t, let Xj be the subsets of X as de ned in Algorithm 2, and  j be the projection matrices of their respective subspaces. We now show that  j and the projection matrix of the subspace spanned by  k are close in operator norm. Lemma 4.5. Let   be the projection matrix of the subspace spanned by the vectors of  k, and for each 1  j  t, let  j be the projection matrix as de ned in Algorithm 2. If m  O(k + ln(qt)), then P    j,   j O         d  m        0.95 Proof. We show that the subspaces spanned by Xj and the true subspace spanned by   are close. Formally, we invoke Lemmata 2.3 and 2.4. This closeness follows from standard matrix concentration inequalities. Fix a j  [t]. Note that Xj can be written as Y j + H, where Y j is the matrix of vectors distributed as N ( 0, k), and H is a matrix of vectors distributed as N ( 0, d k), where  k and  d k are de ned as in Remark 4.2. By Corollary 2.7, with probability at least 1  0.02 t , sk(Y j)    (( m +   k)( p sk( k))) =  ( m +   k) > 0. Therefore, the subspace spanned by Y j is the same as the subspace spanned by  k. So, it suf ces to look at the subspace spanned by Y j. Now, by Corollary 2.7, we know that with probability at least 1  0.02 t ,  Xj  Y j =  H  O(( m +   d) p s1( d k))  O( ( m +   d) p sk( k))  O( ( m +   d)). We wish to invoke Lemma 2.3. Let UDV T be the SVD of Y j, and let  U  D  V T be the SVD of Xj. Now, for a matrix M, let  M denote the projection matrix of the subspace spanned by the columns of M. De ne quantities a,b,z12,z21 as follows. a = smin(UT XjV ) = smin(UT Y jV + UT HV ) = smin(UT Y jV ) (Columns of U are orthogonal to columns of H) = sk(Y j)  (   m +   k)  (   m) b =  UT  XjV  =  UT  Y jV + UT  HV  =  UT  HV  (Columns of U are orthogonal to columns of Y j)  H   O( (   m +   d)) z12 =  UH V  = 0 z21 =  U H V   =  U 1/2 d k( 1/2 d k H) V   18 Now, in the above,  1/2 d k H  Rd m, such that each of its entry is an independent sample from N (0,1). Right-multiplying it by  V makes it a matrix in a k-dimensional subspace of Rm, such that each row is an independent vector from a spherical Gaussian. Using Corol- lary 2.7,  1/2 d k H O(   d +   k)  O(   d) with probability at least 1  0.01 t . Also,  U 1/2 d k  O(  p sk( k))  O( ). This gives us: z21  O(    d). Since a2 > 2b2, we get the following by Lemma 2.3.  Sin( )(U,  U)  az21 + bz12 a2  b2  min{z2 12,z2 21}  O         d  m     Therefore, using Lemma 2.4, and applying the union bound over all j, we get the required result. Let   = O \u0012     d  m \u0013 . We show that the projections of any reference point are close. Corollary 4.6. Let p1,...,pq be the reference points as de ned in Algorithm 2, and let   and  j (for 1  j  t) be projections matrices as de ned in Lemma 4.5. Then P h  i,j, (   j)pi O( (   k + p ln(qt))) i  0.9. Proof. We know from Lemma 4.5 that    j  for all j with probability at least 0.95. For j  [t], let b j be the projection matrix for the union of the jth subspace and the subspace spanned by  k. Lemma 2.10 implies that with probability at least 0.95, for all i,j,  b jpi O(   k+ p ln(qt)). Therefore,  (   j)pi =  (   j)b jpi   j   b jpi O( (   k + p ln(qt))). Hence, the claim. The above corollary shows that the projections of each reference point lie in a ball of radius O(    k). Next, we show that for each reference point, all the projections of the point lie inside a histogram cell with high probability. For notational convenience, since each point in Q is a concatenation of the projection of all reference points on a given subspace, for all i,j, we refer to (0,...,0,Qj (i 1)d+1,...,Qj id,0,...,0)  Rqd (where there are (i  1)d zeroes behind Qj (i 1)d+1, and (q  i)d zeroes after Qj id) as pj i. Lemma 4.7. Let  and   be the length of a histogram cell and the random offset respectively, as de ned in Algorithm 2. Then P[|   Q| = t]  0.8. Thus there exists    that, such that all points in Q lie within  . 19 Proof. Let r = O( (   k + p ln(qt))). This implies that  = 20r q. The random offset could also be viewed as moving along a diagonal of a cell by   p dq. We know that with probability at least 0.8, for each i, all projections of reference point pi lie in a ball of radius r. This means that all the points in Q lie in a ball of radius r q. Then P[|   Q| = t]  P \u0014 1 20      19 20 \u0015 = 1 10. Taking the union bound over all q and the failure of the event in Corollary 4.6, we get the claim. Now, we analyse the sample complexity due to the private algorithm, that is, DP-histograms. Lemma 4.8. Let   be the histogram cell as de ned in Algorithm 2. Suppose Count( ) is the noisy count of   as a result of applying the private histogram. If t  O \u0010log(1/ )   \u0011 , then P \u0014 |Count( )|  t 2 \u0015  0.75. Proof. Lemma 4.7 implies that with probability at least 0.8, for each i, all projections of pi lie in a histogram cell, that is, all points of Q lie in a histogram cell in  . Because of the error bound in Lemma 2.15 and our bound on t, we see at least t 2 points in that cell with probability at least 1  0.05. Therefore, by taking the union bound, the proof is complete. We  nally show that the error of the projection matrix that is output by Algorithm 2 is small. Lemma 4.9. Let b  be the projection matrix as de ned in Algorithm 2, and n be the total number of samples. If  2  O  2n d2k ln(1/ )   min (1 k , 1 ln(k ln(1/ )/ ) )! , n  O(k log(1/ )   + ln(1/ )ln(ln(1/ )/ )   ), and q  O(k) the with probability at least 0.7,  b   . Proof. For each i  [q], let p  i be the projection of pi on to the subspace spanned by  k, bpi be as de ned in the algorithm, and pj i be the projection of pi on to the subspace spanned by the jth subset of X. From Lemma 4.8, we know that all pj i  s are contained in a histogram cell of length  . This implies that p  i is also contained within the same histogram cell. Now, let P = (p  1,...,p  q) and bP = (bp1,...,bpq). Then by above, bP = P + E, where  E F  2  p dq. Therefore,  E 2  p dq. Let E = EP + EP , where EP is the component of E in the subspace spanned by P , and EP be the orthogonal component. Let P   = P + EP . We will be analysing bP with respect to P  . Now, with probability at least 0.95, sk(P )  (   k) due to our choice of q and using Corol- lary 2.7, and sk+1(P ) = 0. So, sk+1(P  ) = 0 because EP is in the same subspace as P . Now, using Lemma 2.2, we know that sk(P  )  sk(P )  EP  (   k) > 0. This means that P   has rank k, so the subspaces spanned by  k and P   are the same. As before, we will try to bound the distance between the subspaces spanned by P   and bP . Note that using Lemma 2.1, we know that sk(P  )  sk(P ) +  EP  O(   k). 20 We wish to invoke Lemma 2.3 again. Let UDV T be the SVD of P  , and let  U  D  V T be the SVD of bP . Now, for a matrix M, let  M denote the projection matrix of the subspace spanned by the columns of M. De ne quantities a,b,z12,z21 as follows. a = smin(UT bP V ) = smin(UT P  V + UT EP V ) = smin(UT P  V ) (Columns of U are orthogonal to columns of EP ) = sk(P  )  (   k) b =  UT  bP V  =  UT  P  V + UT  EP V  =  UT  EP V  (Columns of U are orthogonal to columns of P  )  EP    O(  p dq) z12 =  UEP  V  = 0 z21 =  U EP  V    EP    O(  p dq) Using Lemma 2.3, we get the following.  Sin( )(U,  U)  az21 + bz12 a2  b2  min{z2 12,z2 21}  O \u0010     dk \u0011   This completes our proof. 4.3 Boosting In this subsection, we discuss boosting of error guarantees of Algorithm 2. The approach we use is very similar to the well-known Median-of-Means method: we run the algorithm multiple times, and choose an output that is close to all other  good  outputs. We formalise this in Algorithm 3. Now, we present the main result of this subsection. Theorem 4.10. Let    Rd d be an arbitrary, symmetric, PSD matrix of rank  k  {1,...,d}, and let 0 <   < 1. Suppose   is the projection matrix corresponding to the subspace spanned by the vectors of  k. Then given  2  O  2n d2k ln(1/ )   min (1 k , 1 ln(k ln(1/ )/ ) )! , 21 Algorithm 3: DP Approximate Subspace Estimator Boosted DPASEB , , , , ,k(X) Input: Samples X1,...,Xn  Rd. Parameters  , , , , ,k > 0. Output: Projection matrix b   Rd d of rank k. Set parameters: t  C3 log(1/ ) m  n/t  Split X into t datasets of size m: X1,...,Xt. // Run DPASE t times to get multiple projection matrices. For i  1,...,t b i  DPASE , , , ,k(Xi) // Select a good subspace. For i  1,...,t ci  0 For j  [t] \\ {i} If  b i  b j 2  ci  ci + 1 If ci  0.6t  1 Return b i. // If there were not enough good subspaces, return  . Return  . such that  k+1( )  2 k( ), for every  ,  > 0, and 0 <  ,  < 1, there exists and ( , )-DP algorithm that takes n  O k log(1/ )log(1/ )   + log(1/ )log(log(1/ )/ )log(1/ )   ! samples from N ( 0, ), and outputs a projection matrix b , such that    b  with probability at least 1  . Proof. Privacy holds trivially by Theorem 4.3. We know by Theorem 4.3 that for each i, with probability at least 0.7,  b i  . This means that by Lemma 2.9, with probability at least 1  , at least 0.6t of all the computed projection matrices are accurate. This means that there has to be at least one projection matrix that is close to 0.6t  1 > 0.5t of these accurate projection matrices. So, the algorithm cannot return  . Now, we want to argue that the returned projection matrix is accurate, too. Any projection matrix that is close to at least 0.6t  1 projection matrices must be close to at least one accurate projection matrix (by pigeonhole principle). Therefore, by triangle inequality, it will be close to the true subspace. Therefore, the returned projection matrix is also accurate. 22 References [ABU18] R. Arora, V. Braverman, and J. Upadhyay.  Differentially private robust low- rank approximation . In: Advances in neural information processing systems (2018). [ACGMMTZ16] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang.  Deep learning with differential privacy . In: Proceedings of the 2016 ACM SIGSAC conference on computer and communications security. 2016, pp. 308 318. [ADKMV18] K. Amin, T. Dick, A. Kulesza, A. M. Medina, and S. Vassilvitskii.  Private covariance estimation via iterative eigenvector sampling . In: 2018 NIPS workshop in Privacy-Preserving Machine Learning. Vol. 250. 2018. [BBDS12] J. Blocki, A. Blum, A. Datta, and O. Sheffet.  The Johnson-Lindenstrauss Trans- form Itself Preserves Differential Privacy . In: Proceedings of the 53rd Annual IEEE Symposium on Foundations of Computer Science. FOCS  12. Washington, DC, USA: IEEE Computer Society, 2012, pp. 410 419. [BBNS19] J. B asiok, M. Bun, A. Nikolov, and T. Steinke.  Towards instance-optimal private query release . In: Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms. SIAM. 2019, pp. 2480 2497. [BCMNUW20] R. Bassily, A. Cheu, S. Moran, A. Nikolov, J. Ullman, and S. Wu.  Private query release assisted by public data . In: International Conference on Machine Learning. PMLR. 2020, pp. 695 703. [BDMN05] A. Blum, C. Dwork, F. McSherry, and K. Nissim.  Practical Privacy: The SuLQ Framework . In: Proceedings of the 24th ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems. PODS  05. New York, NY, USA: ACM, 2005, pp. 128 138. [BDRS18] M. Bun, C. Dwork, G. N. Rothblum, and T. Steinke.  Composable and Versatile Privacy via Truncated CDP . In: Proceedings of the 50th Annual ACM Symposium on the Theory of Computing. STOC  18. New York, NY, USA: ACM, 2018, pp. 74  86. [BLR08] A. Blum, K. Ligett, and A. Roth.  A Learning Theory Approach to Non- Interactive Database Privacy . In: STOC. 2008. [BNS16] M. Bun, K. Nissim, and U. Stemmer.  Simultaneous Private Learning of Multi- ple Concepts . In: Proceedings of the 7th Conference on Innovations in Theoretical Computer Science. ITCS  16. New York, NY, USA: ACM, 2016, pp. 369 380. [BS16] M. Bun and T. Steinke.  Concentrated Differential Privacy: Simpli cations, Extensions, and Lower Bounds . In: Proceedings of the 14th Conference on Theory of Cryptography. TCC  16-B. Berlin, Heidelberg: Springer, 2016, pp. 635 658. 23 [BUV14] M. Bun, J. Ullman, and S. Vadhan.  Fingerprinting Codes and the Price of Approximate Differential Privacy . In: Proceedings of the 46th Annual ACM Symposium on the Theory of Computing. STOC  14. New York, NY, USA: ACM, 2014, pp. 1 10. [CSS12] K. Chaudhuri, A. Sarwate, and K. Sinha.  Near-optimal differentially private principal components . In: Advances in Neural Information Processing Systems 25 (2012), pp. 989 997. [CZ16] T. Cai and A. Zhang.  Rate-Optimal Perturbation Bounds for Singular Sub- spaces with Applications to High-Dimensional Statistics . In: The Annals of Statistics 46 (May 2016). [DMNS06] C. Dwork, F. McSherry, K. Nissim, and A. Smith.  Calibrating Noise to Sensi- tivity in Private Data Analysis . In: Proceedings of the 3rd Conference on Theory of Cryptography. TCC  06. Berlin, Heidelberg: Springer, 2006, pp. 265 284. [DSSUV15] C. Dwork, A. Smith, T. Steinke, J. Ullman, and S. Vadhan.  Robust Traceability from Trace Amounts . In: Proceedings of the 56th Annual IEEE Symposium on Foundations of Computer Science. FOCS  15. Washington, DC, USA: IEEE Computer Society, 2015, pp. 650 669. [DTTZ14] C. Dwork, K. Talwar, A. Thakurta, and L. Zhang.  Analyze Gauss: Optimal Bounds for Privacy-Preserving Principal Component Analysis . In: Proceed- ings of the 46th Annual ACM Symposium on the Theory of Computing. STOC  14. New York, NY, USA: ACM, 2014, pp. 11 20. [FT20] Y. Feng and Y. Tu.  How neural networks  nd generalizable solutions: Self- tuned annealing in deep learning . In: arXiv preprint arXiv:2001.01678 (2020). [GARD18] G. Gur-Ari, D. A. Roberts, and E. Dyer.  Gradient descent happens in a tiny subspace . In: arXiv preprint arXiv:1812.04754 (2018). [GDGK20] Q. Geng, W. Ding, R. Guo, and S. Kumar.  Tight Analysis of Privacy and Utility Tradeoff in Approximate Differential Privacy . In: Proceedings of the Twenty Third International Conference on Arti cial Intelligence and Statistics. Ed. by S. Chiappa and R. Calandra. Vol. 108. Proceedings of Machine Learning Research. PMLR, 2020, pp. 89 99. [GGB18] A. Gonem and R. Gilad-Bachrach.  Smooth Sensitivity Based Approach for Differentially Private PCA . In: Algorithmic Learning Theory. ALT  18. JMLR, Inc., 2018, pp. 438 450. [HP13] M. Hardt and E. Price.  The noisy power method: A meta algorithm with applications . In: arXiv preprint arXiv:1311.2495 (2013). [HR10] M. Hardt and G. N. Rothblum.  A multiplicative weights mechanism for privacy-preserving data analysis . In: 2010 IEEE 51st Annual Symposium on Foundations of Computer Science. IEEE. 2010, pp. 61 70. 24 [HR12] M. Hardt and A. Roth.  Beating randomized response on incoherent matrices . In: Proceedings of the forty-fourth annual ACM symposium on Theory of computing. 2012, pp. 1255 1268. [HR13] M. Hardt and A. Roth.  Beyond worst-case analysis in private singular vector computation . In: Proceedings of the forty- fth annual ACM symposium on Theory of computing. 2013, pp. 331 340. [HT10] M. Hardt and K. Talwar.  On the Geometry of Differential Privacy . In: Proceedings of the 42nd Annual ACM Symposium on the Theory of Computing. STOC  10. New York, NY, USA: ACM, 2010, pp. 705 714. [KRRT20] P. Kairouz, M. Ribero, K. Rush, and A. Thakurta. Fast Dimension Independent Private AdaGrad on Publicly Estimated Subspaces. 2020. [KT13] M. Kapralov and K. Talwar.  On Differentially Private Low Rank Approxi- mation . In: Proceedings of the 24th Annual ACM-SIAM Symposium on Discrete Algorithms. SODA  13. Philadelphia, PA, USA: SIAM, 2013, pp. 1395 1414. [LFLY18] C. Li, H. Farkhoor, R. Liu, and J. Yosinski.  Measuring the intrinsic dimension of objective landscapes . In: arXiv preprint arXiv:1804.08838 (2018). [LGZCB20] X. Li, Q. Gu, Y. Zhou, T. Chen, and A. Banerjee.  Hessian based analysis of sgd for deep nets: Dynamics and generalization . In: Proceedings of the 2020 SIAM International Conference on Data Mining. SIAM. 2020, pp. 190 198. [LXTSG17] H. Li, Z. Xu, G. Taylor, C. Studer, and T. Goldstein.  Visualizing the loss landscape of neural nets . In: arXiv preprint arXiv:1712.09913 (2017). [MM09] F. McSherry and I. Mironov.  Differentially private recommender systems: Building privacy into the net ix prize contenders . In: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. 2009, pp. 627 636. [MT07] F. McSherry and K. Talwar.  Mechanism Design via Differential Privacy . In: Proceedings of the 48th Annual IEEE Symposium on Foundations of Computer Sci- ence. FOCS  07. Washington, DC, USA: IEEE Computer Society, 2007, pp. 94  103. [NRS07] K. Nissim, S. Raskhodnikova, and A. Smith.  Smooth Sensitivity and Sam- pling in Private Data Analysis . In: Proceedings of the 39th Annual ACM Sympo- sium on the Theory of Computing. STOC  07. New York, NY, USA: ACM, 2007, pp. 75 84. [NS06] A. Narayanan and V. Shmatikov.  How to break anonymity of the net ix prize dataset . In: arXiv preprint cs/0610105 (2006). [She19] O. Sheffet.  Old techniques in differentially private linear regression . In: Algorithmic Learning Theory. PMLR. 2019, pp. 789 827. [SU17] T. Steinke and J. Ullman.  Between Pure and Approximate Differential Pri- vacy . In: The Journal of Privacy and Con dentiality 7.2 (2017), pp. 3 22. 25 [Ull15] J. Ullman.  Private multiplicative weights beyond linear queries . In: Pro- ceedings of the 34th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems. 2015, pp. 303 312. [Vad17] S. Vadhan.  The Complexity of Differential Privacy . In: Tutorials on the Foun- dations of Cryptography: Dedicated to Oded Goldreich. Ed. by Y. Lindell. Cham, Switzerland: Springer International Publishing AG, 2017. Chap. 7, pp. 347  450. [Ver18] R. Vershynin. High-Dimensional Probability: An Introduction with Applications in Data Science. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, 2018. [WSCHT16] L. Wei, A. D. Sarwate, J. Corander, A. Hero, and V. Tarokh.  Analysis of a privacy-preserving PCA algorithm using random matrix theory . In: 2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP). IEEE. 2016, pp. 1335 1339. [ZWB20] Y. Zhou, Z. S. Wu, and A. Banerjee.  Bypassing the ambient dimension: Private sgd with gradient subspace identi cation . In: arXiv preprint arXiv:2007.03813 (2020). 26"
    }
]